2024-09-03 22:15:40,757 - mmdet3d - INFO - Config:
seed = 0
deterministic = False
checkpoint_config = dict(interval=1, max_keep_ckpts=1)
log_config = dict(
    interval=50,
    hooks=[dict(type='TextLoggerHook'),
           dict(type='TensorboardLoggerHook')])
load_from = 'pretrained/lidar-only-det.pth'
resume_from = None
cudnn_benchmark = False
fp16 = dict(loss_scale=dict(growth_interval=2000))
max_epochs = 10
runner = dict(type='CustomEpochBasedRunner', max_epochs=10)
dataset_type = 'NuScenesDataset'
dataset_root = '/scratch/jmeng18/V2X-SIM/'
gt_paste_stop_epoch = -1
reduce_beams = 32
load_dim = 5
use_dim = 5
load_augmented = None
point_cloud_range = [-108.0, -108.0, -10.0, 108.0, 108.0, 6.0]
voxel_size = [0.15, 0.15, 0.4]
image_size = [256, 704]
augment2d = dict(
    resize=[[0.38, 0.55], [0.48, 0.48]],
    rotate=[-5.4, 5.4],
    gridmask=dict(prob=0.0, fixed_prob=True))
augment3d = dict(
    scale=[0.9, 1.1], rotate=[-0.78539816, 0.78539816], translate=0.5)
object_classes = ['car']
map_classes = [
    'drivable_area', 'ped_crossing', 'walkway', 'stop_line', 'carpark_area'
]
input_modality = dict(
    use_lidar=True,
    use_camera=True,
    use_radar=False,
    use_map=False,
    use_external=False)
train_pipeline = [
    dict(type='LoadMultiViewImageFromFiles', to_float32=True),
    dict(
        type='LoadPointsFromFile',
        coord_type='LIDAR',
        load_dim=5,
        use_dim=5,
        reduce_beams=32,
        load_augmented=None),
    dict(
        type='LoadPointsFromMultiSweeps',
        sweeps_num=0,
        load_dim=5,
        use_dim=5,
        reduce_beams=32,
        pad_empty_sweeps=True,
        remove_close=True,
        load_augmented=None),
    dict(
        type='LoadAnnotations3D',
        with_bbox_3d=True,
        with_label_3d=True,
        with_attr_label=False),
    dict(
        type='ObjectPaste',
        stop_epoch=-1,
        db_sampler=dict(
            dataset_root='/scratch/jmeng18/V2X-SIM/',
            info_path='/scratch/jmeng18/V2X-SIM/nuscenes_dbinfos_train.pkl',
            rate=1.0,
            prepare=dict(
                filter_by_difficulty=[-1], filter_by_min_points=dict(car=5)),
            classes=['car'],
            sample_groups=dict(car=2),
            points_loader=dict(
                type='LoadPointsFromFile',
                coord_type='LIDAR',
                load_dim=5,
                use_dim=5,
                reduce_beams=32))),
    dict(
        type='ImageAug3D',
        final_dim=[256, 704],
        resize_lim=[0.38, 0.55],
        bot_pct_lim=[0.0, 0.0],
        rot_lim=[-5.4, 5.4],
        rand_flip=True,
        is_train=True),
    dict(
        type='GlobalRotScaleTrans',
        resize_lim=[0.9, 1.1],
        rot_lim=[-0.78539816, 0.78539816],
        trans_lim=0.5,
        is_train=True),
    dict(type='RandomFlip3D'),
    dict(
        type='PointsRangeFilter',
        point_cloud_range=[-108.0, -108.0, -10.0, 108.0, 108.0, 6.0]),
    dict(
        type='ObjectRangeFilter',
        point_cloud_range=[-108.0, -108.0, -10.0, 108.0, 108.0, 6.0]),
    dict(type='ObjectNameFilter', classes=['car']),
    dict(
        type='ImageNormalize',
        mean=[0.485, 0.456, 0.406],
        std=[0.229, 0.224, 0.225]),
    dict(
        type='GridMask',
        use_h=True,
        use_w=True,
        max_epoch=10,
        rotate=1,
        offset=False,
        ratio=0.5,
        mode=1,
        prob=0.0,
        fixed_prob=True),
    dict(type='PointShuffle'),
    dict(type='DefaultFormatBundle3D', classes=['car']),
    dict(
        type='Collect3D',
        keys=['img', 'points', 'gt_bboxes_3d', 'gt_labels_3d'],
        meta_keys=[
            'camera_intrinsics', 'camera2ego', 'lidar2ego', 'lidar2camera',
            'lidar2image', 'camera2lidar', 'img_aug_matrix', 'lidar_aug_matrix'
        ]),
    dict(type='GTDepth', keyframe_only=True)
]
test_pipeline = [
    dict(type='LoadMultiViewImageFromFiles', to_float32=True),
    dict(
        type='LoadPointsFromFile',
        coord_type='LIDAR',
        load_dim=5,
        use_dim=5,
        reduce_beams=32,
        load_augmented=None),
    dict(
        type='LoadPointsFromMultiSweeps',
        sweeps_num=9,
        load_dim=5,
        use_dim=5,
        reduce_beams=32,
        pad_empty_sweeps=True,
        remove_close=True,
        load_augmented=None),
    dict(
        type='LoadAnnotations3D',
        with_bbox_3d=True,
        with_label_3d=True,
        with_attr_label=False),
    dict(
        type='ImageAug3D',
        final_dim=[256, 704],
        resize_lim=[0.48, 0.48],
        bot_pct_lim=[0.0, 0.0],
        rot_lim=[0.0, 0.0],
        rand_flip=False,
        is_train=False),
    dict(
        type='GlobalRotScaleTrans',
        resize_lim=[1.0, 1.0],
        rot_lim=[0.0, 0.0],
        trans_lim=0.0,
        is_train=False),
    dict(
        type='PointsRangeFilter',
        point_cloud_range=[-108.0, -108.0, -10.0, 108.0, 108.0, 6.0]),
    dict(
        type='ImageNormalize',
        mean=[0.485, 0.456, 0.406],
        std=[0.229, 0.224, 0.225]),
    dict(type='DefaultFormatBundle3D', classes=['car']),
    dict(
        type='Collect3D',
        keys=['img', 'points', 'gt_bboxes_3d', 'gt_labels_3d'],
        meta_keys=[
            'camera_intrinsics', 'camera2ego', 'lidar2ego', 'lidar2camera',
            'lidar2image', 'camera2lidar', 'img_aug_matrix', 'lidar_aug_matrix'
        ]),
    dict(type='GTDepth', keyframe_only=True)
]
data = dict(
    samples_per_gpu=1,
    workers_per_gpu=1,
    train=dict(
        type='CBGSDataset',
        dataset=dict(
            type='NuScenesDataset',
            dataset_root='/scratch/jmeng18/V2X-SIM/',
            ann_file='/scratch/jmeng18/V2X-SIM/nuscenes_infos_train.pkl',
            pipeline=[
                dict(type='LoadMultiViewImageFromFiles', to_float32=True),
                dict(
                    type='LoadPointsFromFile',
                    coord_type='LIDAR',
                    load_dim=5,
                    use_dim=5,
                    reduce_beams=32,
                    load_augmented=None),
                dict(
                    type='LoadPointsFromMultiSweeps',
                    sweeps_num=0,
                    load_dim=5,
                    use_dim=5,
                    reduce_beams=32,
                    pad_empty_sweeps=True,
                    remove_close=True,
                    load_augmented=None),
                dict(
                    type='LoadAnnotations3D',
                    with_bbox_3d=True,
                    with_label_3d=True,
                    with_attr_label=False),
                dict(
                    type='ObjectPaste',
                    stop_epoch=-1,
                    db_sampler=dict(
                        dataset_root='/scratch/jmeng18/V2X-SIM/',
                        info_path=
                        '/scratch/jmeng18/V2X-SIM/nuscenes_dbinfos_train.pkl',
                        rate=1.0,
                        prepare=dict(
                            filter_by_difficulty=[-1],
                            filter_by_min_points=dict(car=5)),
                        classes=['car'],
                        sample_groups=dict(car=2),
                        points_loader=dict(
                            type='LoadPointsFromFile',
                            coord_type='LIDAR',
                            load_dim=5,
                            use_dim=5,
                            reduce_beams=32))),
                dict(
                    type='ImageAug3D',
                    final_dim=[256, 704],
                    resize_lim=[0.38, 0.55],
                    bot_pct_lim=[0.0, 0.0],
                    rot_lim=[-5.4, 5.4],
                    rand_flip=True,
                    is_train=True),
                dict(
                    type='GlobalRotScaleTrans',
                    resize_lim=[0.9, 1.1],
                    rot_lim=[-0.78539816, 0.78539816],
                    trans_lim=0.5,
                    is_train=True),
                dict(type='RandomFlip3D'),
                dict(
                    type='PointsRangeFilter',
                    point_cloud_range=[
                        -108.0, -108.0, -10.0, 108.0, 108.0, 6.0
                    ]),
                dict(
                    type='ObjectRangeFilter',
                    point_cloud_range=[
                        -108.0, -108.0, -10.0, 108.0, 108.0, 6.0
                    ]),
                dict(type='ObjectNameFilter', classes=['car']),
                dict(
                    type='ImageNormalize',
                    mean=[0.485, 0.456, 0.406],
                    std=[0.229, 0.224, 0.225]),
                dict(
                    type='GridMask',
                    use_h=True,
                    use_w=True,
                    max_epoch=10,
                    rotate=1,
                    offset=False,
                    ratio=0.5,
                    mode=1,
                    prob=0.0,
                    fixed_prob=True),
                dict(type='PointShuffle'),
                dict(type='DefaultFormatBundle3D', classes=['car']),
                dict(
                    type='Collect3D',
                    keys=['img', 'points', 'gt_bboxes_3d', 'gt_labels_3d'],
                    meta_keys=[
                        'camera_intrinsics', 'camera2ego', 'lidar2ego',
                        'lidar2camera', 'lidar2image', 'camera2lidar',
                        'img_aug_matrix', 'lidar_aug_matrix'
                    ]),
                dict(type='GTDepth', keyframe_only=True)
            ],
            object_classes=['car'],
            map_classes=[
                'drivable_area', 'ped_crossing', 'walkway', 'stop_line',
                'carpark_area'
            ],
            modality=dict(
                use_lidar=True,
                use_camera=True,
                use_radar=False,
                use_map=False,
                use_external=False),
            test_mode=False,
            use_valid_flag=True,
            box_type_3d='LiDAR')),
    val=dict(
        type='NuScenesDataset',
        dataset_root='/scratch/jmeng18/V2X-SIM/',
        ann_file='/scratch/jmeng18/V2X-SIM/nuscenes_infos_val.pkl',
        pipeline=[
            dict(type='LoadMultiViewImageFromFiles', to_float32=True),
            dict(
                type='LoadPointsFromFile',
                coord_type='LIDAR',
                load_dim=5,
                use_dim=5,
                reduce_beams=32,
                load_augmented=None),
            dict(
                type='LoadPointsFromMultiSweeps',
                sweeps_num=9,
                load_dim=5,
                use_dim=5,
                reduce_beams=32,
                pad_empty_sweeps=True,
                remove_close=True,
                load_augmented=None),
            dict(
                type='LoadAnnotations3D',
                with_bbox_3d=True,
                with_label_3d=True,
                with_attr_label=False),
            dict(
                type='ImageAug3D',
                final_dim=[256, 704],
                resize_lim=[0.48, 0.48],
                bot_pct_lim=[0.0, 0.0],
                rot_lim=[0.0, 0.0],
                rand_flip=False,
                is_train=False),
            dict(
                type='GlobalRotScaleTrans',
                resize_lim=[1.0, 1.0],
                rot_lim=[0.0, 0.0],
                trans_lim=0.0,
                is_train=False),
            dict(
                type='PointsRangeFilter',
                point_cloud_range=[-108.0, -108.0, -10.0, 108.0, 108.0, 6.0]),
            dict(
                type='ImageNormalize',
                mean=[0.485, 0.456, 0.406],
                std=[0.229, 0.224, 0.225]),
            dict(type='DefaultFormatBundle3D', classes=['car']),
            dict(
                type='Collect3D',
                keys=['img', 'points', 'gt_bboxes_3d', 'gt_labels_3d'],
                meta_keys=[
                    'camera_intrinsics', 'camera2ego', 'lidar2ego',
                    'lidar2camera', 'lidar2image', 'camera2lidar',
                    'img_aug_matrix', 'lidar_aug_matrix'
                ]),
            dict(type='GTDepth', keyframe_only=True)
        ],
        object_classes=['car'],
        map_classes=[
            'drivable_area', 'ped_crossing', 'walkway', 'stop_line',
            'carpark_area'
        ],
        modality=dict(
            use_lidar=True,
            use_camera=True,
            use_radar=False,
            use_map=False,
            use_external=False),
        test_mode=False,
        box_type_3d='LiDAR'),
    test=dict(
        type='NuScenesDataset',
        dataset_root='/scratch/jmeng18/V2X-SIM/',
        ann_file='/scratch/jmeng18/V2X-SIM/nuscenes_infos_val.pkl',
        pipeline=[
            dict(type='LoadMultiViewImageFromFiles', to_float32=True),
            dict(
                type='LoadPointsFromFile',
                coord_type='LIDAR',
                load_dim=5,
                use_dim=5,
                reduce_beams=32,
                load_augmented=None),
            dict(
                type='LoadPointsFromMultiSweeps',
                sweeps_num=9,
                load_dim=5,
                use_dim=5,
                reduce_beams=32,
                pad_empty_sweeps=True,
                remove_close=True,
                load_augmented=None),
            dict(
                type='LoadAnnotations3D',
                with_bbox_3d=True,
                with_label_3d=True,
                with_attr_label=False),
            dict(
                type='ImageAug3D',
                final_dim=[256, 704],
                resize_lim=[0.48, 0.48],
                bot_pct_lim=[0.0, 0.0],
                rot_lim=[0.0, 0.0],
                rand_flip=False,
                is_train=False),
            dict(
                type='GlobalRotScaleTrans',
                resize_lim=[1.0, 1.0],
                rot_lim=[0.0, 0.0],
                trans_lim=0.0,
                is_train=False),
            dict(
                type='PointsRangeFilter',
                point_cloud_range=[-108.0, -108.0, -10.0, 108.0, 108.0, 6.0]),
            dict(
                type='ImageNormalize',
                mean=[0.485, 0.456, 0.406],
                std=[0.229, 0.224, 0.225]),
            dict(type='DefaultFormatBundle3D', classes=['car']),
            dict(
                type='Collect3D',
                keys=['img', 'points', 'gt_bboxes_3d', 'gt_labels_3d'],
                meta_keys=[
                    'camera_intrinsics', 'camera2ego', 'lidar2ego',
                    'lidar2camera', 'lidar2image', 'camera2lidar',
                    'img_aug_matrix', 'lidar_aug_matrix'
                ]),
            dict(type='GTDepth', keyframe_only=True)
        ],
        object_classes=['car'],
        map_classes=[
            'drivable_area', 'ped_crossing', 'walkway', 'stop_line',
            'carpark_area'
        ],
        modality=dict(
            use_lidar=True,
            use_camera=True,
            use_radar=False,
            use_map=False,
            use_external=False),
        test_mode=True,
        box_type_3d='LiDAR'))
evaluation = dict(
    interval=1,
    pipeline=[
        dict(type='LoadMultiViewImageFromFiles', to_float32=True),
        dict(
            type='LoadPointsFromFile',
            coord_type='LIDAR',
            load_dim=5,
            use_dim=5,
            reduce_beams=32,
            load_augmented=None),
        dict(
            type='LoadPointsFromMultiSweeps',
            sweeps_num=9,
            load_dim=5,
            use_dim=5,
            reduce_beams=32,
            pad_empty_sweeps=True,
            remove_close=True,
            load_augmented=None),
        dict(
            type='LoadAnnotations3D',
            with_bbox_3d=True,
            with_label_3d=True,
            with_attr_label=False),
        dict(
            type='ImageAug3D',
            final_dim=[256, 704],
            resize_lim=[0.48, 0.48],
            bot_pct_lim=[0.0, 0.0],
            rot_lim=[0.0, 0.0],
            rand_flip=False,
            is_train=False),
        dict(
            type='GlobalRotScaleTrans',
            resize_lim=[1.0, 1.0],
            rot_lim=[0.0, 0.0],
            trans_lim=0.0,
            is_train=False),
        dict(
            type='PointsRangeFilter',
            point_cloud_range=[-108.0, -108.0, -10.0, 108.0, 108.0, 6.0]),
        dict(
            type='ImageNormalize',
            mean=[0.485, 0.456, 0.406],
            std=[0.229, 0.224, 0.225]),
        dict(type='DefaultFormatBundle3D', classes=['car']),
        dict(
            type='Collect3D',
            keys=['img', 'points', 'gt_bboxes_3d', 'gt_labels_3d'],
            meta_keys=[
                'camera_intrinsics', 'camera2ego', 'lidar2ego', 'lidar2camera',
                'lidar2image', 'camera2lidar', 'img_aug_matrix',
                'lidar_aug_matrix'
            ]),
        dict(type='GTDepth', keyframe_only=True)
    ])
radar_sweeps = 6
radar_max_points = 2500
radar_use_dims = [
    0, 1, 2, 5, 8, 9, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31,
    32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50,
    51, 52, 53, 54, 55, 56
]
radar_compensate_velocity = True
radar_filtering = 'none'
radar_voxel_size = [0.8, 0.8, 8]
radar_jitter = 0
radar_normalize = False
model = dict(
    type='BEVFusion',
    encoders=dict(
        camera=dict(
            neck=dict(
                type='GeneralizedLSSFPN',
                in_channels=[192, 384, 768],
                out_channels=256,
                start_level=0,
                num_outs=3,
                norm_cfg=dict(type='BN2d', requires_grad=True),
                act_cfg=dict(type='ReLU', inplace=True),
                upsample_cfg=dict(mode='bilinear', align_corners=False)),
            vtransform=dict(
                type='DepthLSSTransform',
                in_channels=256,
                out_channels=80,
                image_size=[256, 704],
                feature_size=[32, 88],
                xbound=[-108.0, 108.0, 0.6],
                ybound=[-108.0, 108.0, 0.6],
                zbound=[-10.0, 10.0, 20.0],
                dbound=[1.0, 60.0, 0.5],
                downsample=2),
            backbone=dict(
                type='SwinTransformer',
                embed_dims=96,
                depths=[2, 2, 6, 2],
                num_heads=[3, 6, 12, 24],
                window_size=7,
                mlp_ratio=4,
                qkv_bias=True,
                qk_scale=None,
                drop_rate=0.0,
                attn_drop_rate=0.0,
                drop_path_rate=0.2,
                patch_norm=True,
                out_indices=[1, 2, 3],
                with_cp=False,
                convert_weights=True,
                init_cfg=dict(
                    type='Pretrained',
                    checkpoint='pretrained/swint-nuimages-pretrained.pth'))),
        lidar=dict(
            voxelize=dict(
                max_num_points=10,
                point_cloud_range=[-108.0, -108.0, -10.0, 108.0, 108.0, 6.0],
                voxel_size=[0.15, 0.15, 0.4],
                max_voxels=[120000, 160000]),
            backbone=dict(
                type='SparseEncoder',
                in_channels=5,
                sparse_shape=[1440, 1440, 41],
                output_channels=128,
                order=['conv', 'norm', 'act'],
                encoder_channels=[[16, 16, 32], [32, 32, 64], [64, 64, 128],
                                  [128, 128]],
                encoder_paddings=[[0, 0, 1], [0, 0, 1], [0, 0, [1, 1, 0]],
                                  [0, 0]],
                block_type='basicblock')),
        infra=dict(
            neck=dict(
                type='GeneralizedLSSFPN',
                in_channels=[192, 384, 768],
                out_channels=256,
                start_level=0,
                num_outs=3,
                norm_cfg=dict(type='BN2d', requires_grad=True),
                act_cfg=dict(type='ReLU', inplace=True),
                upsample_cfg=dict(mode='bilinear', align_corners=False)),
            vtransform=dict(
                type='DepthLSSTransform',
                in_channels=256,
                out_channels=80,
                image_size=[256, 704],
                feature_size=[32, 88],
                xbound=[-108.0, 108.0, 0.6],
                ybound=[-108.0, 108.0, 0.6],
                zbound=[-10.0, 10.0, 20.0],
                dbound=[1.0, 60.0, 0.5],
                downsample=2),
            backbone=dict(
                type='SwinTransformer',
                embed_dims=96,
                depths=[2, 2, 6, 2],
                num_heads=[3, 6, 12, 24],
                window_size=7,
                mlp_ratio=4,
                qkv_bias=True,
                qk_scale=None,
                drop_rate=0.0,
                attn_drop_rate=0.0,
                drop_path_rate=0.2,
                patch_norm=True,
                out_indices=[1, 2, 3],
                with_cp=False,
                convert_weights=True,
                init_cfg=dict(
                    type='Pretrained',
                    checkpoint=
                    'https://github.com/SwinTransformer/storage/releases/download/v1.0.0/swin_tiny_patch4_window7_224.pth'
                )))),
    fuser=dict(type='ConvFuser', in_channels=[80, 256, 80], out_channels=256),
    heads=dict(
        map=None,
        object=dict(
            type='TransFusionHead',
            num_proposals=200,
            auxiliary=True,
            in_channels=512,
            hidden_channel=128,
            num_classes=1,
            num_decoder_layers=1,
            num_heads=8,
            nms_kernel_size=3,
            ffn_channel=256,
            dropout=0.1,
            bn_momentum=0.1,
            activation='relu',
            train_cfg=dict(
                dataset='nuScenes',
                point_cloud_range=[-108.0, -108.0, -10.0, 108.0, 108.0, 6.0],
                grid_size=[1440, 1440, 41],
                voxel_size=[0.15, 0.15, 0.4],
                out_size_factor=8,
                gaussian_overlap=0.1,
                min_radius=2,
                pos_weight=-1,
                code_weights=[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0],
                assigner=dict(
                    type='HungarianAssigner3D',
                    iou_calculator=dict(
                        type='BboxOverlaps3D', coordinate='lidar'),
                    cls_cost=dict(
                        type='FocalLossCost',
                        gamma=2.0,
                        alpha=0.25,
                        weight=0.15),
                    reg_cost=dict(type='BBoxBEVL1Cost', weight=0.25),
                    iou_cost=dict(type='IoU3DCost', weight=0.25))),
            test_cfg=dict(
                dataset='nuScenes',
                grid_size=[1440, 1440, 41],
                out_size_factor=8,
                voxel_size=[0.15, 0.15],
                pc_range=[-108.0, -108.0],
                nms_type=None),
            common_heads=dict(
                center=[2, 2],
                height=[1, 2],
                dim=[3, 2],
                rot=[2, 2],
                vel=[2, 2]),
            bbox_coder=dict(
                type='TransFusionBBoxCoder',
                pc_range=[-108.0, -108.0],
                post_center_range=[-122.4, -122.4, -20.0, 122.4, 122.4, 20.0],
                score_threshold=0.0,
                out_size_factor=8,
                voxel_size=[0.15, 0.15]),
            loss_cls=dict(
                type='FocalLoss',
                use_sigmoid=True,
                gamma=2.0,
                alpha=0.25,
                reduction='mean',
                loss_weight=1.0),
            loss_heatmap=dict(
                type='GaussianFocalLoss', reduction='mean', loss_weight=1.0),
            loss_bbox=dict(type='L1Loss', reduction='mean',
                           loss_weight=0.25))),
    decoder=dict(
        backbone=dict(
            type='SECOND',
            in_channels=256,
            out_channels=[128, 256],
            layer_nums=[5, 5],
            layer_strides=[1, 2],
            norm_cfg=dict(type='BN', eps=0.001, momentum=0.01),
            conv_cfg=dict(type='Conv2d', bias=False)),
        neck=dict(
            type='SECONDFPN',
            in_channels=[128, 256],
            out_channels=[256, 256],
            upsample_strides=[1, 2],
            norm_cfg=dict(type='BN', eps=0.001, momentum=0.01),
            upsample_cfg=dict(type='deconv', bias=False),
            use_conv_for_no_stride=True)))
optimizer = dict(type='AdamW', lr=0.0001, weight_decay=0.01)
optimizer_config = dict(grad_clip=dict(max_norm=35, norm_type=2))
lr_config = dict(
    policy='CosineAnnealing',
    warmup='linear',
    warmup_iters=500,
    warmup_ratio=0.33333333,
    min_lr_ratio=1e-07)
momentum_config = dict(policy='cyclic')
run_dir = 'train_result_infra_long_full'

2024-09-03 22:15:40,758 - mmdet3d - INFO - Set random seed to 0, deterministic mode: False
2024-09-03 22:15:48,035 - mmdet3d - INFO - load 349483 car database infos
2024-09-03 22:15:48,035 - mmdet3d - INFO - load 157002 bicycle database infos
2024-09-03 22:15:48,036 - mmdet3d - INFO - load 40210 motorcycle database infos
2024-09-03 22:15:48,036 - mmdet3d - INFO - load 16943 vehicle.emergency.police database infos
2024-09-03 22:15:48,871 - mmdet3d - INFO - After filter database:
2024-09-03 22:15:48,883 - mmdet3d - INFO - load 170227 car database infos
2024-09-03 22:15:48,884 - mmdet3d - INFO - load 157002 bicycle database infos
2024-09-03 22:15:48,885 - mmdet3d - INFO - load 40210 motorcycle database infos
2024-09-03 22:15:48,886 - mmdet3d - INFO - load 16943 vehicle.emergency.police database infos
2024-09-03 22:15:51,455 - mmdet3d - INFO - Model:
BEVFusion(
  (encoders): ModuleDict(
    (camera): ModuleDict(
      (backbone): SwinTransformer(
        (patch_embed): PatchEmbed(
          (adap_padding): AdaptivePadding()
          (projection): Conv2d(3, 96, kernel_size=(4, 4), stride=(4, 4))
          (norm): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
        )
        (drop_after_pos): Dropout(p=0.0, inplace=False)
        (stages): ModuleList(
          (0): SwinBlockSequence(
            (blocks): ModuleList(
              (0): SwinBlock(
                (norm1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
                (attn): ShiftWindowMSA(
                  (w_msa): WindowMSA(
                    (qkv): Linear(in_features=96, out_features=288, bias=True)
                    (attn_drop): Dropout(p=0.0, inplace=False)
                    (proj): Linear(in_features=96, out_features=96, bias=True)
                    (proj_drop): Dropout(p=0.0, inplace=False)
                    (softmax): Softmax(dim=-1)
                  )
                  (drop): DropPath()
                )
                (norm2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
                (ffn): FFN(
                  (activate): GELU()
                  (layers): Sequential(
                    (0): Sequential(
                      (0): Linear(in_features=96, out_features=384, bias=True)
                      (1): GELU()
                      (2): Dropout(p=0.0, inplace=False)
                    )
                    (1): Linear(in_features=384, out_features=96, bias=True)
                    (2): Dropout(p=0.0, inplace=False)
                  )
                  (dropout_layer): DropPath()
                )
              )
              (1): SwinBlock(
                (norm1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
                (attn): ShiftWindowMSA(
                  (w_msa): WindowMSA(
                    (qkv): Linear(in_features=96, out_features=288, bias=True)
                    (attn_drop): Dropout(p=0.0, inplace=False)
                    (proj): Linear(in_features=96, out_features=96, bias=True)
                    (proj_drop): Dropout(p=0.0, inplace=False)
                    (softmax): Softmax(dim=-1)
                  )
                  (drop): DropPath()
                )
                (norm2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
                (ffn): FFN(
                  (activate): GELU()
                  (layers): Sequential(
                    (0): Sequential(
                      (0): Linear(in_features=96, out_features=384, bias=True)
                      (1): GELU()
                      (2): Dropout(p=0.0, inplace=False)
                    )
                    (1): Linear(in_features=384, out_features=96, bias=True)
                    (2): Dropout(p=0.0, inplace=False)
                  )
                  (dropout_layer): DropPath()
                )
              )
            )
            (downsample): PatchMerging(
              (adap_padding): AdaptivePadding()
              (sampler): Unfold(kernel_size=(2, 2), dilation=(1, 1), padding=(0, 0), stride=(2, 2))
              (norm): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
              (reduction): Linear(in_features=384, out_features=192, bias=False)
            )
          )
          (1): SwinBlockSequence(
            (blocks): ModuleList(
              (0): SwinBlock(
                (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                (attn): ShiftWindowMSA(
                  (w_msa): WindowMSA(
                    (qkv): Linear(in_features=192, out_features=576, bias=True)
                    (attn_drop): Dropout(p=0.0, inplace=False)
                    (proj): Linear(in_features=192, out_features=192, bias=True)
                    (proj_drop): Dropout(p=0.0, inplace=False)
                    (softmax): Softmax(dim=-1)
                  )
                  (drop): DropPath()
                )
                (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                (ffn): FFN(
                  (activate): GELU()
                  (layers): Sequential(
                    (0): Sequential(
                      (0): Linear(in_features=192, out_features=768, bias=True)
                      (1): GELU()
                      (2): Dropout(p=0.0, inplace=False)
                    )
                    (1): Linear(in_features=768, out_features=192, bias=True)
                    (2): Dropout(p=0.0, inplace=False)
                  )
                  (dropout_layer): DropPath()
                )
              )
              (1): SwinBlock(
                (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                (attn): ShiftWindowMSA(
                  (w_msa): WindowMSA(
                    (qkv): Linear(in_features=192, out_features=576, bias=True)
                    (attn_drop): Dropout(p=0.0, inplace=False)
                    (proj): Linear(in_features=192, out_features=192, bias=True)
                    (proj_drop): Dropout(p=0.0, inplace=False)
                    (softmax): Softmax(dim=-1)
                  )
                  (drop): DropPath()
                )
                (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                (ffn): FFN(
                  (activate): GELU()
                  (layers): Sequential(
                    (0): Sequential(
                      (0): Linear(in_features=192, out_features=768, bias=True)
                      (1): GELU()
                      (2): Dropout(p=0.0, inplace=False)
                    )
                    (1): Linear(in_features=768, out_features=192, bias=True)
                    (2): Dropout(p=0.0, inplace=False)
                  )
                  (dropout_layer): DropPath()
                )
              )
            )
            (downsample): PatchMerging(
              (adap_padding): AdaptivePadding()
              (sampler): Unfold(kernel_size=(2, 2), dilation=(1, 1), padding=(0, 0), stride=(2, 2))
              (norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (reduction): Linear(in_features=768, out_features=384, bias=False)
            )
          )
          (2): SwinBlockSequence(
            (blocks): ModuleList(
              (0): SwinBlock(
                (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
                (attn): ShiftWindowMSA(
                  (w_msa): WindowMSA(
                    (qkv): Linear(in_features=384, out_features=1152, bias=True)
                    (attn_drop): Dropout(p=0.0, inplace=False)
                    (proj): Linear(in_features=384, out_features=384, bias=True)
                    (proj_drop): Dropout(p=0.0, inplace=False)
                    (softmax): Softmax(dim=-1)
                  )
                  (drop): DropPath()
                )
                (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
                (ffn): FFN(
                  (activate): GELU()
                  (layers): Sequential(
                    (0): Sequential(
                      (0): Linear(in_features=384, out_features=1536, bias=True)
                      (1): GELU()
                      (2): Dropout(p=0.0, inplace=False)
                    )
                    (1): Linear(in_features=1536, out_features=384, bias=True)
                    (2): Dropout(p=0.0, inplace=False)
                  )
                  (dropout_layer): DropPath()
                )
              )
              (1): SwinBlock(
                (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
                (attn): ShiftWindowMSA(
                  (w_msa): WindowMSA(
                    (qkv): Linear(in_features=384, out_features=1152, bias=True)
                    (attn_drop): Dropout(p=0.0, inplace=False)
                    (proj): Linear(in_features=384, out_features=384, bias=True)
                    (proj_drop): Dropout(p=0.0, inplace=False)
                    (softmax): Softmax(dim=-1)
                  )
                  (drop): DropPath()
                )
                (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
                (ffn): FFN(
                  (activate): GELU()
                  (layers): Sequential(
                    (0): Sequential(
                      (0): Linear(in_features=384, out_features=1536, bias=True)
                      (1): GELU()
                      (2): Dropout(p=0.0, inplace=False)
                    )
                    (1): Linear(in_features=1536, out_features=384, bias=True)
                    (2): Dropout(p=0.0, inplace=False)
                  )
                  (dropout_layer): DropPath()
                )
              )
              (2): SwinBlock(
                (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
                (attn): ShiftWindowMSA(
                  (w_msa): WindowMSA(
                    (qkv): Linear(in_features=384, out_features=1152, bias=True)
                    (attn_drop): Dropout(p=0.0, inplace=False)
                    (proj): Linear(in_features=384, out_features=384, bias=True)
                    (proj_drop): Dropout(p=0.0, inplace=False)
                    (softmax): Softmax(dim=-1)
                  )
                  (drop): DropPath()
                )
                (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
                (ffn): FFN(
                  (activate): GELU()
                  (layers): Sequential(
                    (0): Sequential(
                      (0): Linear(in_features=384, out_features=1536, bias=True)
                      (1): GELU()
                      (2): Dropout(p=0.0, inplace=False)
                    )
                    (1): Linear(in_features=1536, out_features=384, bias=True)
                    (2): Dropout(p=0.0, inplace=False)
                  )
                  (dropout_layer): DropPath()
                )
              )
              (3): SwinBlock(
                (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
                (attn): ShiftWindowMSA(
                  (w_msa): WindowMSA(
                    (qkv): Linear(in_features=384, out_features=1152, bias=True)
                    (attn_drop): Dropout(p=0.0, inplace=False)
                    (proj): Linear(in_features=384, out_features=384, bias=True)
                    (proj_drop): Dropout(p=0.0, inplace=False)
                    (softmax): Softmax(dim=-1)
                  )
                  (drop): DropPath()
                )
                (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
                (ffn): FFN(
                  (activate): GELU()
                  (layers): Sequential(
                    (0): Sequential(
                      (0): Linear(in_features=384, out_features=1536, bias=True)
                      (1): GELU()
                      (2): Dropout(p=0.0, inplace=False)
                    )
                    (1): Linear(in_features=1536, out_features=384, bias=True)
                    (2): Dropout(p=0.0, inplace=False)
                  )
                  (dropout_layer): DropPath()
                )
              )
              (4): SwinBlock(
                (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
                (attn): ShiftWindowMSA(
                  (w_msa): WindowMSA(
                    (qkv): Linear(in_features=384, out_features=1152, bias=True)
                    (attn_drop): Dropout(p=0.0, inplace=False)
                    (proj): Linear(in_features=384, out_features=384, bias=True)
                    (proj_drop): Dropout(p=0.0, inplace=False)
                    (softmax): Softmax(dim=-1)
                  )
                  (drop): DropPath()
                )
                (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
                (ffn): FFN(
                  (activate): GELU()
                  (layers): Sequential(
                    (0): Sequential(
                      (0): Linear(in_features=384, out_features=1536, bias=True)
                      (1): GELU()
                      (2): Dropout(p=0.0, inplace=False)
                    )
                    (1): Linear(in_features=1536, out_features=384, bias=True)
                    (2): Dropout(p=0.0, inplace=False)
                  )
                  (dropout_layer): DropPath()
                )
              )
              (5): SwinBlock(
                (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
                (attn): ShiftWindowMSA(
                  (w_msa): WindowMSA(
                    (qkv): Linear(in_features=384, out_features=1152, bias=True)
                    (attn_drop): Dropout(p=0.0, inplace=False)
                    (proj): Linear(in_features=384, out_features=384, bias=True)
                    (proj_drop): Dropout(p=0.0, inplace=False)
                    (softmax): Softmax(dim=-1)
                  )
                  (drop): DropPath()
                )
                (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
                (ffn): FFN(
                  (activate): GELU()
                  (layers): Sequential(
                    (0): Sequential(
                      (0): Linear(in_features=384, out_features=1536, bias=True)
                      (1): GELU()
                      (2): Dropout(p=0.0, inplace=False)
                    )
                    (1): Linear(in_features=1536, out_features=384, bias=True)
                    (2): Dropout(p=0.0, inplace=False)
                  )
                  (dropout_layer): DropPath()
                )
              )
            )
            (downsample): PatchMerging(
              (adap_padding): AdaptivePadding()
              (sampler): Unfold(kernel_size=(2, 2), dilation=(1, 1), padding=(0, 0), stride=(2, 2))
              (norm): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)
              (reduction): Linear(in_features=1536, out_features=768, bias=False)
            )
          )
          (3): SwinBlockSequence(
            (blocks): ModuleList(
              (0): SwinBlock(
                (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (attn): ShiftWindowMSA(
                  (w_msa): WindowMSA(
                    (qkv): Linear(in_features=768, out_features=2304, bias=True)
                    (attn_drop): Dropout(p=0.0, inplace=False)
                    (proj): Linear(in_features=768, out_features=768, bias=True)
                    (proj_drop): Dropout(p=0.0, inplace=False)
                    (softmax): Softmax(dim=-1)
                  )
                  (drop): DropPath()
                )
                (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (ffn): FFN(
                  (activate): GELU()
                  (layers): Sequential(
                    (0): Sequential(
                      (0): Linear(in_features=768, out_features=3072, bias=True)
                      (1): GELU()
                      (2): Dropout(p=0.0, inplace=False)
                    )
                    (1): Linear(in_features=3072, out_features=768, bias=True)
                    (2): Dropout(p=0.0, inplace=False)
                  )
                  (dropout_layer): DropPath()
                )
              )
              (1): SwinBlock(
                (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (attn): ShiftWindowMSA(
                  (w_msa): WindowMSA(
                    (qkv): Linear(in_features=768, out_features=2304, bias=True)
                    (attn_drop): Dropout(p=0.0, inplace=False)
                    (proj): Linear(in_features=768, out_features=768, bias=True)
                    (proj_drop): Dropout(p=0.0, inplace=False)
                    (softmax): Softmax(dim=-1)
                  )
                  (drop): DropPath()
                )
                (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (ffn): FFN(
                  (activate): GELU()
                  (layers): Sequential(
                    (0): Sequential(
                      (0): Linear(in_features=768, out_features=3072, bias=True)
                      (1): GELU()
                      (2): Dropout(p=0.0, inplace=False)
                    )
                    (1): Linear(in_features=3072, out_features=768, bias=True)
                    (2): Dropout(p=0.0, inplace=False)
                  )
                  (dropout_layer): DropPath()
                )
              )
            )
          )
        )
        (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
        (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
        (norm3): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      )
      init_cfg={'type': 'Pretrained', 'checkpoint': 'pretrained/swint-nuimages-pretrained.pth'}
      (neck): GeneralizedLSSFPN(
        (lateral_convs): ModuleList(
          (0): ConvModule(
            (conv): Conv2d(448, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (activate): ReLU(inplace=True)
          )
          (1): ConvModule(
            (conv): Conv2d(1152, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (activate): ReLU(inplace=True)
          )
        )
        (fpn_convs): ModuleList(
          (0): ConvModule(
            (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (activate): ReLU(inplace=True)
          )
          (1): ConvModule(
            (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (activate): ReLU(inplace=True)
          )
        )
      )
      (vtransform): DepthLSSTransform(
        (dtransform): Sequential(
          (0): Conv2d(1, 8, kernel_size=(1, 1), stride=(1, 1))
          (1): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Conv2d(8, 32, kernel_size=(5, 5), stride=(4, 4), padding=(2, 2))
          (4): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): ReLU(inplace=True)
          (6): Conv2d(32, 64, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2))
          (7): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (8): ReLU(inplace=True)
        )
        (depthnet): Sequential(
          (0): Conv2d(320, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): ReLU(inplace=True)
          (6): Conv2d(256, 198, kernel_size=(1, 1), stride=(1, 1))
        )
        (downsample): Sequential(
          (0): Conv2d(80, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (1): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Conv2d(80, 80, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
          (4): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): ReLU(inplace=True)
          (6): Conv2d(80, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (7): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (8): ReLU(inplace=True)
        )
      )
    )
    (lidar): ModuleDict(
      (voxelize): Voxelization(voxel_size=[0.15, 0.15, 0.4], point_cloud_range=[-108.0, -108.0, -10.0, 108.0, 108.0, 6.0], max_num_points=10, max_voxels=(120000, 160000), deterministic=True)
      (backbone): SparseEncoder(
        (conv_input): SparseSequential(
          (0): SubMConv3d()
          (1): BatchNorm1d(16, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
        )
        (encoder_layers): SparseSequential(
          (encoder_layer1): SparseSequential(
            (0): SparseBasicBlock(
              (conv1): SubMConv3d()
              (bn1): BatchNorm1d(16, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
              (conv2): SubMConv3d()
              (bn2): BatchNorm1d(16, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
              (relu): ReLU(inplace=True)
            )
            (1): SparseBasicBlock(
              (conv1): SubMConv3d()
              (bn1): BatchNorm1d(16, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
              (conv2): SubMConv3d()
              (bn2): BatchNorm1d(16, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
              (relu): ReLU(inplace=True)
            )
            (2): SparseSequential(
              (0): SparseConv3d()
              (1): BatchNorm1d(32, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
              (2): ReLU(inplace=True)
            )
          )
          (encoder_layer2): SparseSequential(
            (0): SparseBasicBlock(
              (conv1): SubMConv3d()
              (bn1): BatchNorm1d(32, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
              (conv2): SubMConv3d()
              (bn2): BatchNorm1d(32, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
              (relu): ReLU(inplace=True)
            )
            (1): SparseBasicBlock(
              (conv1): SubMConv3d()
              (bn1): BatchNorm1d(32, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
              (conv2): SubMConv3d()
              (bn2): BatchNorm1d(32, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
              (relu): ReLU(inplace=True)
            )
            (2): SparseSequential(
              (0): SparseConv3d()
              (1): BatchNorm1d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
              (2): ReLU(inplace=True)
            )
          )
          (encoder_layer3): SparseSequential(
            (0): SparseBasicBlock(
              (conv1): SubMConv3d()
              (bn1): BatchNorm1d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
              (conv2): SubMConv3d()
              (bn2): BatchNorm1d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
              (relu): ReLU(inplace=True)
            )
            (1): SparseBasicBlock(
              (conv1): SubMConv3d()
              (bn1): BatchNorm1d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
              (conv2): SubMConv3d()
              (bn2): BatchNorm1d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
              (relu): ReLU(inplace=True)
            )
            (2): SparseSequential(
              (0): SparseConv3d()
              (1): BatchNorm1d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
              (2): ReLU(inplace=True)
            )
          )
          (encoder_layer4): SparseSequential(
            (0): SparseBasicBlock(
              (conv1): SubMConv3d()
              (bn1): BatchNorm1d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
              (conv2): SubMConv3d()
              (bn2): BatchNorm1d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
              (relu): ReLU(inplace=True)
            )
            (1): SparseBasicBlock(
              (conv1): SubMConv3d()
              (bn1): BatchNorm1d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
              (conv2): SubMConv3d()
              (bn2): BatchNorm1d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
              (relu): ReLU(inplace=True)
            )
          )
        )
        (conv_out): SparseSequential(
          (0): SparseConv3d()
          (1): BatchNorm1d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
        )
      )
    )
    (infra): ModuleDict(
      (backbone): SwinTransformer(
        (patch_embed): PatchEmbed(
          (adap_padding): AdaptivePadding()
          (projection): Conv2d(3, 96, kernel_size=(4, 4), stride=(4, 4))
          (norm): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
        )
        (drop_after_pos): Dropout(p=0.0, inplace=False)
        (stages): ModuleList(
          (0): SwinBlockSequence(
            (blocks): ModuleList(
              (0): SwinBlock(
                (norm1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
                (attn): ShiftWindowMSA(
                  (w_msa): WindowMSA(
                    (qkv): Linear(in_features=96, out_features=288, bias=True)
                    (attn_drop): Dropout(p=0.0, inplace=False)
                    (proj): Linear(in_features=96, out_features=96, bias=True)
                    (proj_drop): Dropout(p=0.0, inplace=False)
                    (softmax): Softmax(dim=-1)
                  )
                  (drop): DropPath()
                )
                (norm2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
                (ffn): FFN(
                  (activate): GELU()
                  (layers): Sequential(
                    (0): Sequential(
                      (0): Linear(in_features=96, out_features=384, bias=True)
                      (1): GELU()
                      (2): Dropout(p=0.0, inplace=False)
                    )
                    (1): Linear(in_features=384, out_features=96, bias=True)
                    (2): Dropout(p=0.0, inplace=False)
                  )
                  (dropout_layer): DropPath()
                )
              )
              (1): SwinBlock(
                (norm1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
                (attn): ShiftWindowMSA(
                  (w_msa): WindowMSA(
                    (qkv): Linear(in_features=96, out_features=288, bias=True)
                    (attn_drop): Dropout(p=0.0, inplace=False)
                    (proj): Linear(in_features=96, out_features=96, bias=True)
                    (proj_drop): Dropout(p=0.0, inplace=False)
                    (softmax): Softmax(dim=-1)
                  )
                  (drop): DropPath()
                )
                (norm2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
                (ffn): FFN(
                  (activate): GELU()
                  (layers): Sequential(
                    (0): Sequential(
                      (0): Linear(in_features=96, out_features=384, bias=True)
                      (1): GELU()
                      (2): Dropout(p=0.0, inplace=False)
                    )
                    (1): Linear(in_features=384, out_features=96, bias=True)
                    (2): Dropout(p=0.0, inplace=False)
                  )
                  (dropout_layer): DropPath()
                )
              )
            )
            (downsample): PatchMerging(
              (adap_padding): AdaptivePadding()
              (sampler): Unfold(kernel_size=(2, 2), dilation=(1, 1), padding=(0, 0), stride=(2, 2))
              (norm): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
              (reduction): Linear(in_features=384, out_features=192, bias=False)
            )
          )
          (1): SwinBlockSequence(
            (blocks): ModuleList(
              (0): SwinBlock(
                (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                (attn): ShiftWindowMSA(
                  (w_msa): WindowMSA(
                    (qkv): Linear(in_features=192, out_features=576, bias=True)
                    (attn_drop): Dropout(p=0.0, inplace=False)
                    (proj): Linear(in_features=192, out_features=192, bias=True)
                    (proj_drop): Dropout(p=0.0, inplace=False)
                    (softmax): Softmax(dim=-1)
                  )
                  (drop): DropPath()
                )
                (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                (ffn): FFN(
                  (activate): GELU()
                  (layers): Sequential(
                    (0): Sequential(
                      (0): Linear(in_features=192, out_features=768, bias=True)
                      (1): GELU()
                      (2): Dropout(p=0.0, inplace=False)
                    )
                    (1): Linear(in_features=768, out_features=192, bias=True)
                    (2): Dropout(p=0.0, inplace=False)
                  )
                  (dropout_layer): DropPath()
                )
              )
              (1): SwinBlock(
                (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                (attn): ShiftWindowMSA(
                  (w_msa): WindowMSA(
                    (qkv): Linear(in_features=192, out_features=576, bias=True)
                    (attn_drop): Dropout(p=0.0, inplace=False)
                    (proj): Linear(in_features=192, out_features=192, bias=True)
                    (proj_drop): Dropout(p=0.0, inplace=False)
                    (softmax): Softmax(dim=-1)
                  )
                  (drop): DropPath()
                )
                (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                (ffn): FFN(
                  (activate): GELU()
                  (layers): Sequential(
                    (0): Sequential(
                      (0): Linear(in_features=192, out_features=768, bias=True)
                      (1): GELU()
                      (2): Dropout(p=0.0, inplace=False)
                    )
                    (1): Linear(in_features=768, out_features=192, bias=True)
                    (2): Dropout(p=0.0, inplace=False)
                  )
                  (dropout_layer): DropPath()
                )
              )
            )
            (downsample): PatchMerging(
              (adap_padding): AdaptivePadding()
              (sampler): Unfold(kernel_size=(2, 2), dilation=(1, 1), padding=(0, 0), stride=(2, 2))
              (norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (reduction): Linear(in_features=768, out_features=384, bias=False)
            )
          )
          (2): SwinBlockSequence(
            (blocks): ModuleList(
              (0): SwinBlock(
                (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
                (attn): ShiftWindowMSA(
                  (w_msa): WindowMSA(
                    (qkv): Linear(in_features=384, out_features=1152, bias=True)
                    (attn_drop): Dropout(p=0.0, inplace=False)
                    (proj): Linear(in_features=384, out_features=384, bias=True)
                    (proj_drop): Dropout(p=0.0, inplace=False)
                    (softmax): Softmax(dim=-1)
                  )
                  (drop): DropPath()
                )
                (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
                (ffn): FFN(
                  (activate): GELU()
                  (layers): Sequential(
                    (0): Sequential(
                      (0): Linear(in_features=384, out_features=1536, bias=True)
                      (1): GELU()
                      (2): Dropout(p=0.0, inplace=False)
                    )
                    (1): Linear(in_features=1536, out_features=384, bias=True)
                    (2): Dropout(p=0.0, inplace=False)
                  )
                  (dropout_layer): DropPath()
                )
              )
              (1): SwinBlock(
                (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
                (attn): ShiftWindowMSA(
                  (w_msa): WindowMSA(
                    (qkv): Linear(in_features=384, out_features=1152, bias=True)
                    (attn_drop): Dropout(p=0.0, inplace=False)
                    (proj): Linear(in_features=384, out_features=384, bias=True)
                    (proj_drop): Dropout(p=0.0, inplace=False)
                    (softmax): Softmax(dim=-1)
                  )
                  (drop): DropPath()
                )
                (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
                (ffn): FFN(
                  (activate): GELU()
                  (layers): Sequential(
                    (0): Sequential(
                      (0): Linear(in_features=384, out_features=1536, bias=True)
                      (1): GELU()
                      (2): Dropout(p=0.0, inplace=False)
                    )
                    (1): Linear(in_features=1536, out_features=384, bias=True)
                    (2): Dropout(p=0.0, inplace=False)
                  )
                  (dropout_layer): DropPath()
                )
              )
              (2): SwinBlock(
                (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
                (attn): ShiftWindowMSA(
                  (w_msa): WindowMSA(
                    (qkv): Linear(in_features=384, out_features=1152, bias=True)
                    (attn_drop): Dropout(p=0.0, inplace=False)
                    (proj): Linear(in_features=384, out_features=384, bias=True)
                    (proj_drop): Dropout(p=0.0, inplace=False)
                    (softmax): Softmax(dim=-1)
                  )
                  (drop): DropPath()
                )
                (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
                (ffn): FFN(
                  (activate): GELU()
                  (layers): Sequential(
                    (0): Sequential(
                      (0): Linear(in_features=384, out_features=1536, bias=True)
                      (1): GELU()
                      (2): Dropout(p=0.0, inplace=False)
                    )
                    (1): Linear(in_features=1536, out_features=384, bias=True)
                    (2): Dropout(p=0.0, inplace=False)
                  )
                  (dropout_layer): DropPath()
                )
              )
              (3): SwinBlock(
                (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
                (attn): ShiftWindowMSA(
                  (w_msa): WindowMSA(
                    (qkv): Linear(in_features=384, out_features=1152, bias=True)
                    (attn_drop): Dropout(p=0.0, inplace=False)
                    (proj): Linear(in_features=384, out_features=384, bias=True)
                    (proj_drop): Dropout(p=0.0, inplace=False)
                    (softmax): Softmax(dim=-1)
                  )
                  (drop): DropPath()
                )
                (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
                (ffn): FFN(
                  (activate): GELU()
                  (layers): Sequential(
                    (0): Sequential(
                      (0): Linear(in_features=384, out_features=1536, bias=True)
                      (1): GELU()
                      (2): Dropout(p=0.0, inplace=False)
                    )
                    (1): Linear(in_features=1536, out_features=384, bias=True)
                    (2): Dropout(p=0.0, inplace=False)
                  )
                  (dropout_layer): DropPath()
                )
              )
              (4): SwinBlock(
                (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
                (attn): ShiftWindowMSA(
                  (w_msa): WindowMSA(
                    (qkv): Linear(in_features=384, out_features=1152, bias=True)
                    (attn_drop): Dropout(p=0.0, inplace=False)
                    (proj): Linear(in_features=384, out_features=384, bias=True)
                    (proj_drop): Dropout(p=0.0, inplace=False)
                    (softmax): Softmax(dim=-1)
                  )
                  (drop): DropPath()
                )
                (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
                (ffn): FFN(
                  (activate): GELU()
                  (layers): Sequential(
                    (0): Sequential(
                      (0): Linear(in_features=384, out_features=1536, bias=True)
                      (1): GELU()
                      (2): Dropout(p=0.0, inplace=False)
                    )
                    (1): Linear(in_features=1536, out_features=384, bias=True)
                    (2): Dropout(p=0.0, inplace=False)
                  )
                  (dropout_layer): DropPath()
                )
              )
              (5): SwinBlock(
                (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
                (attn): ShiftWindowMSA(
                  (w_msa): WindowMSA(
                    (qkv): Linear(in_features=384, out_features=1152, bias=True)
                    (attn_drop): Dropout(p=0.0, inplace=False)
                    (proj): Linear(in_features=384, out_features=384, bias=True)
                    (proj_drop): Dropout(p=0.0, inplace=False)
                    (softmax): Softmax(dim=-1)
                  )
                  (drop): DropPath()
                )
                (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
                (ffn): FFN(
                  (activate): GELU()
                  (layers): Sequential(
                    (0): Sequential(
                      (0): Linear(in_features=384, out_features=1536, bias=True)
                      (1): GELU()
                      (2): Dropout(p=0.0, inplace=False)
                    )
                    (1): Linear(in_features=1536, out_features=384, bias=True)
                    (2): Dropout(p=0.0, inplace=False)
                  )
                  (dropout_layer): DropPath()
                )
              )
            )
            (downsample): PatchMerging(
              (adap_padding): AdaptivePadding()
              (sampler): Unfold(kernel_size=(2, 2), dilation=(1, 1), padding=(0, 0), stride=(2, 2))
              (norm): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)
              (reduction): Linear(in_features=1536, out_features=768, bias=False)
            )
          )
          (3): SwinBlockSequence(
            (blocks): ModuleList(
              (0): SwinBlock(
                (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (attn): ShiftWindowMSA(
                  (w_msa): WindowMSA(
                    (qkv): Linear(in_features=768, out_features=2304, bias=True)
                    (attn_drop): Dropout(p=0.0, inplace=False)
                    (proj): Linear(in_features=768, out_features=768, bias=True)
                    (proj_drop): Dropout(p=0.0, inplace=False)
                    (softmax): Softmax(dim=-1)
                  )
                  (drop): DropPath()
                )
                (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (ffn): FFN(
                  (activate): GELU()
                  (layers): Sequential(
                    (0): Sequential(
                      (0): Linear(in_features=768, out_features=3072, bias=True)
                      (1): GELU()
                      (2): Dropout(p=0.0, inplace=False)
                    )
                    (1): Linear(in_features=3072, out_features=768, bias=True)
                    (2): Dropout(p=0.0, inplace=False)
                  )
                  (dropout_layer): DropPath()
                )
              )
              (1): SwinBlock(
                (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (attn): ShiftWindowMSA(
                  (w_msa): WindowMSA(
                    (qkv): Linear(in_features=768, out_features=2304, bias=True)
                    (attn_drop): Dropout(p=0.0, inplace=False)
                    (proj): Linear(in_features=768, out_features=768, bias=True)
                    (proj_drop): Dropout(p=0.0, inplace=False)
                    (softmax): Softmax(dim=-1)
                  )
                  (drop): DropPath()
                )
                (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (ffn): FFN(
                  (activate): GELU()
                  (layers): Sequential(
                    (0): Sequential(
                      (0): Linear(in_features=768, out_features=3072, bias=True)
                      (1): GELU()
                      (2): Dropout(p=0.0, inplace=False)
                    )
                    (1): Linear(in_features=3072, out_features=768, bias=True)
                    (2): Dropout(p=0.0, inplace=False)
                  )
                  (dropout_layer): DropPath()
                )
              )
            )
          )
        )
        (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
        (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
        (norm3): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      )
      init_cfg={'type': 'Pretrained', 'checkpoint': 'https://github.com/SwinTransformer/storage/releases/download/v1.0.0/swin_tiny_patch4_window7_224.pth'}
      (neck): GeneralizedLSSFPN(
        (lateral_convs): ModuleList(
          (0): ConvModule(
            (conv): Conv2d(448, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (activate): ReLU(inplace=True)
          )
          (1): ConvModule(
            (conv): Conv2d(1152, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (activate): ReLU(inplace=True)
          )
        )
        (fpn_convs): ModuleList(
          (0): ConvModule(
            (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (activate): ReLU(inplace=True)
          )
          (1): ConvModule(
            (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (activate): ReLU(inplace=True)
          )
        )
      )
      (vtransform): DepthLSSTransform(
        (dtransform): Sequential(
          (0): Conv2d(1, 8, kernel_size=(1, 1), stride=(1, 1))
          (1): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Conv2d(8, 32, kernel_size=(5, 5), stride=(4, 4), padding=(2, 2))
          (4): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): ReLU(inplace=True)
          (6): Conv2d(32, 64, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2))
          (7): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (8): ReLU(inplace=True)
        )
        (depthnet): Sequential(
          (0): Conv2d(320, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): ReLU(inplace=True)
          (6): Conv2d(256, 198, kernel_size=(1, 1), stride=(1, 1))
        )
        (downsample): Sequential(
          (0): Conv2d(80, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (1): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Conv2d(80, 80, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
          (4): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): ReLU(inplace=True)
          (6): Conv2d(80, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (7): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (8): ReLU(inplace=True)
        )
      )
    )
  )
  (fuser): ConvFuser(
    (0): Conv2d(416, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU(inplace=True)
  )
  (decoder): ModuleDict(
    (backbone): SECOND(
      (blocks): ModuleList(
        (0): Sequential(
          (0): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (1): BatchNorm2d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (4): BatchNorm2d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
          (5): ReLU(inplace=True)
          (6): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (7): BatchNorm2d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
          (8): ReLU(inplace=True)
          (9): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (10): BatchNorm2d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
          (11): ReLU(inplace=True)
          (12): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (13): BatchNorm2d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
          (14): ReLU(inplace=True)
          (15): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (16): BatchNorm2d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
          (17): ReLU(inplace=True)
        )
        (1): Sequential(
          (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
          (1): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (4): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
          (5): ReLU(inplace=True)
          (6): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (7): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
          (8): ReLU(inplace=True)
          (9): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (10): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
          (11): ReLU(inplace=True)
          (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (13): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
          (14): ReLU(inplace=True)
          (15): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (16): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
          (17): ReLU(inplace=True)
        )
      )
    )
    init_cfg={'type': 'Kaiming', 'layer': 'Conv2d'}
    (neck): SECONDFPN(
      (deblocks): ModuleList(
        (0): Sequential(
          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
        )
        (1): Sequential(
          (0): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2), bias=False)
          (1): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
        )
      )
    )
    init_cfg=[{'type': 'Kaiming', 'layer': 'ConvTranspose2d'}, {'type': 'Constant', 'layer': 'NaiveSyncBatchNorm2d', 'val': 1.0}]
  )
  (heads): ModuleDict(
    (object): TransFusionHead(
      (loss_cls): FocalLoss()
      (loss_bbox): L1Loss()
      (loss_iou): VarifocalLoss()
      (loss_heatmap): GaussianFocalLoss()
      (shared_conv): Conv2d(512, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (heatmap_head): Sequential(
        (0): ConvModule(
          (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (1): Conv2d(128, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      )
      (class_encoding): Conv1d(1, 128, kernel_size=(1,), stride=(1,))
      (decoder): ModuleList(
        (0): TransformerDecoderLayer(
          (self_attn): MultiheadAttention(
            (out_proj): Linear(in_features=128, out_features=128, bias=True)
          )
          (multihead_attn): MultiheadAttention(
            (out_proj): Linear(in_features=128, out_features=128, bias=True)
          )
          (linear1): Linear(in_features=128, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear2): Linear(in_features=256, out_features=128, bias=True)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (norm3): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (dropout1): Dropout(p=0.1, inplace=False)
          (dropout2): Dropout(p=0.1, inplace=False)
          (dropout3): Dropout(p=0.1, inplace=False)
          (self_posembed): PositionEmbeddingLearned(
            (position_embedding_head): Sequential(
              (0): Conv1d(2, 128, kernel_size=(1,), stride=(1,))
              (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): ReLU(inplace=True)
              (3): Conv1d(128, 128, kernel_size=(1,), stride=(1,))
            )
          )
          (cross_posembed): PositionEmbeddingLearned(
            (position_embedding_head): Sequential(
              (0): Conv1d(2, 128, kernel_size=(1,), stride=(1,))
              (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): ReLU(inplace=True)
              (3): Conv1d(128, 128, kernel_size=(1,), stride=(1,))
            )
          )
        )
      )
      (prediction_heads): ModuleList(
        (0): FFN(
          (center): Sequential(
            (0): ConvModule(
              (conv): Conv1d(128, 64, kernel_size=(1,), stride=(1,), bias=False)
              (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (activate): ReLU(inplace=True)
            )
            (1): Conv1d(64, 2, kernel_size=(1,), stride=(1,))
          )
          (height): Sequential(
            (0): ConvModule(
              (conv): Conv1d(128, 64, kernel_size=(1,), stride=(1,), bias=False)
              (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (activate): ReLU(inplace=True)
            )
            (1): Conv1d(64, 1, kernel_size=(1,), stride=(1,))
          )
          (dim): Sequential(
            (0): ConvModule(
              (conv): Conv1d(128, 64, kernel_size=(1,), stride=(1,), bias=False)
              (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (activate): ReLU(inplace=True)
            )
            (1): Conv1d(64, 3, kernel_size=(1,), stride=(1,))
          )
          (rot): Sequential(
            (0): ConvModule(
              (conv): Conv1d(128, 64, kernel_size=(1,), stride=(1,), bias=False)
              (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (activate): ReLU(inplace=True)
            )
            (1): Conv1d(64, 2, kernel_size=(1,), stride=(1,))
          )
          (vel): Sequential(
            (0): ConvModule(
              (conv): Conv1d(128, 64, kernel_size=(1,), stride=(1,), bias=False)
              (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (activate): ReLU(inplace=True)
            )
            (1): Conv1d(64, 2, kernel_size=(1,), stride=(1,))
          )
          (heatmap): Sequential(
            (0): ConvModule(
              (conv): Conv1d(128, 64, kernel_size=(1,), stride=(1,), bias=False)
              (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (activate): ReLU(inplace=True)
            )
            (1): Conv1d(64, 1, kernel_size=(1,), stride=(1,))
          )
        )
      )
    )
  )
)
2024-09-03 22:15:54,857 - mmdet3d - INFO - load checkpoint from local path: pretrained/lidar-only-det.pth
2024-09-03 22:15:56,058 - mmdet3d - WARNING - The model and loaded state dict do not match exactly

size mismatch for heads.object.heatmap_head.1.weight: copying a param with shape torch.Size([10, 128, 3, 3]) from checkpoint, the shape in current model is torch.Size([1, 128, 3, 3]).
size mismatch for heads.object.heatmap_head.1.bias: copying a param with shape torch.Size([10]) from checkpoint, the shape in current model is torch.Size([1]).
size mismatch for heads.object.class_encoding.weight: copying a param with shape torch.Size([128, 10, 1]) from checkpoint, the shape in current model is torch.Size([128, 1, 1]).
size mismatch for heads.object.prediction_heads.0.heatmap.1.weight: copying a param with shape torch.Size([10, 64, 1]) from checkpoint, the shape in current model is torch.Size([1, 64, 1]).
size mismatch for heads.object.prediction_heads.0.heatmap.1.bias: copying a param with shape torch.Size([10]) from checkpoint, the shape in current model is torch.Size([1]).
missing keys in source state_dict: encoders.camera.backbone.patch_embed.projection.weight, encoders.camera.backbone.patch_embed.projection.bias, encoders.camera.backbone.patch_embed.norm.weight, encoders.camera.backbone.patch_embed.norm.bias, encoders.camera.backbone.stages.0.blocks.0.norm1.weight, encoders.camera.backbone.stages.0.blocks.0.norm1.bias, encoders.camera.backbone.stages.0.blocks.0.attn.w_msa.relative_position_bias_table, encoders.camera.backbone.stages.0.blocks.0.attn.w_msa.relative_position_index, encoders.camera.backbone.stages.0.blocks.0.attn.w_msa.qkv.weight, encoders.camera.backbone.stages.0.blocks.0.attn.w_msa.qkv.bias, encoders.camera.backbone.stages.0.blocks.0.attn.w_msa.proj.weight, encoders.camera.backbone.stages.0.blocks.0.attn.w_msa.proj.bias, encoders.camera.backbone.stages.0.blocks.0.norm2.weight, encoders.camera.backbone.stages.0.blocks.0.norm2.bias, encoders.camera.backbone.stages.0.blocks.0.ffn.layers.0.0.weight, encoders.camera.backbone.stages.0.blocks.0.ffn.layers.0.0.bias, encoders.camera.backbone.stages.0.blocks.0.ffn.layers.1.weight, encoders.camera.backbone.stages.0.blocks.0.ffn.layers.1.bias, encoders.camera.backbone.stages.0.blocks.1.norm1.weight, encoders.camera.backbone.stages.0.blocks.1.norm1.bias, encoders.camera.backbone.stages.0.blocks.1.attn.w_msa.relative_position_bias_table, encoders.camera.backbone.stages.0.blocks.1.attn.w_msa.relative_position_index, encoders.camera.backbone.stages.0.blocks.1.attn.w_msa.qkv.weight, encoders.camera.backbone.stages.0.blocks.1.attn.w_msa.qkv.bias, encoders.camera.backbone.stages.0.blocks.1.attn.w_msa.proj.weight, encoders.camera.backbone.stages.0.blocks.1.attn.w_msa.proj.bias, encoders.camera.backbone.stages.0.blocks.1.norm2.weight, encoders.camera.backbone.stages.0.blocks.1.norm2.bias, encoders.camera.backbone.stages.0.blocks.1.ffn.layers.0.0.weight, encoders.camera.backbone.stages.0.blocks.1.ffn.layers.0.0.bias, encoders.camera.backbone.stages.0.blocks.1.ffn.layers.1.weight, encoders.camera.backbone.stages.0.blocks.1.ffn.layers.1.bias, encoders.camera.backbone.stages.0.downsample.norm.weight, encoders.camera.backbone.stages.0.downsample.norm.bias, encoders.camera.backbone.stages.0.downsample.reduction.weight, encoders.camera.backbone.stages.1.blocks.0.norm1.weight, encoders.camera.backbone.stages.1.blocks.0.norm1.bias, encoders.camera.backbone.stages.1.blocks.0.attn.w_msa.relative_position_bias_table, encoders.camera.backbone.stages.1.blocks.0.attn.w_msa.relative_position_index, encoders.camera.backbone.stages.1.blocks.0.attn.w_msa.qkv.weight, encoders.camera.backbone.stages.1.blocks.0.attn.w_msa.qkv.bias, encoders.camera.backbone.stages.1.blocks.0.attn.w_msa.proj.weight, encoders.camera.backbone.stages.1.blocks.0.attn.w_msa.proj.bias, encoders.camera.backbone.stages.1.blocks.0.norm2.weight, encoders.camera.backbone.stages.1.blocks.0.norm2.bias, encoders.camera.backbone.stages.1.blocks.0.ffn.layers.0.0.weight, encoders.camera.backbone.stages.1.blocks.0.ffn.layers.0.0.bias, encoders.camera.backbone.stages.1.blocks.0.ffn.layers.1.weight, encoders.camera.backbone.stages.1.blocks.0.ffn.layers.1.bias, encoders.camera.backbone.stages.1.blocks.1.norm1.weight, encoders.camera.backbone.stages.1.blocks.1.norm1.bias, encoders.camera.backbone.stages.1.blocks.1.attn.w_msa.relative_position_bias_table, encoders.camera.backbone.stages.1.blocks.1.attn.w_msa.relative_position_index, encoders.camera.backbone.stages.1.blocks.1.attn.w_msa.qkv.weight, encoders.camera.backbone.stages.1.blocks.1.attn.w_msa.qkv.bias, encoders.camera.backbone.stages.1.blocks.1.attn.w_msa.proj.weight, encoders.camera.backbone.stages.1.blocks.1.attn.w_msa.proj.bias, encoders.camera.backbone.stages.1.blocks.1.norm2.weight, encoders.camera.backbone.stages.1.blocks.1.norm2.bias, encoders.camera.backbone.stages.1.blocks.1.ffn.layers.0.0.weight, encoders.camera.backbone.stages.1.blocks.1.ffn.layers.0.0.bias, encoders.camera.backbone.stages.1.blocks.1.ffn.layers.1.weight, encoders.camera.backbone.stages.1.blocks.1.ffn.layers.1.bias, encoders.camera.backbone.stages.1.downsample.norm.weight, encoders.camera.backbone.stages.1.downsample.norm.bias, encoders.camera.backbone.stages.1.downsample.reduction.weight, encoders.camera.backbone.stages.2.blocks.0.norm1.weight, encoders.camera.backbone.stages.2.blocks.0.norm1.bias, encoders.camera.backbone.stages.2.blocks.0.attn.w_msa.relative_position_bias_table, encoders.camera.backbone.stages.2.blocks.0.attn.w_msa.relative_position_index, encoders.camera.backbone.stages.2.blocks.0.attn.w_msa.qkv.weight, encoders.camera.backbone.stages.2.blocks.0.attn.w_msa.qkv.bias, encoders.camera.backbone.stages.2.blocks.0.attn.w_msa.proj.weight, encoders.camera.backbone.stages.2.blocks.0.attn.w_msa.proj.bias, encoders.camera.backbone.stages.2.blocks.0.norm2.weight, encoders.camera.backbone.stages.2.blocks.0.norm2.bias, encoders.camera.backbone.stages.2.blocks.0.ffn.layers.0.0.weight, encoders.camera.backbone.stages.2.blocks.0.ffn.layers.0.0.bias, encoders.camera.backbone.stages.2.blocks.0.ffn.layers.1.weight, encoders.camera.backbone.stages.2.blocks.0.ffn.layers.1.bias, encoders.camera.backbone.stages.2.blocks.1.norm1.weight, encoders.camera.backbone.stages.2.blocks.1.norm1.bias, encoders.camera.backbone.stages.2.blocks.1.attn.w_msa.relative_position_bias_table, encoders.camera.backbone.stages.2.blocks.1.attn.w_msa.relative_position_index, encoders.camera.backbone.stages.2.blocks.1.attn.w_msa.qkv.weight, encoders.camera.backbone.stages.2.blocks.1.attn.w_msa.qkv.bias, encoders.camera.backbone.stages.2.blocks.1.attn.w_msa.proj.weight, encoders.camera.backbone.stages.2.blocks.1.attn.w_msa.proj.bias, encoders.camera.backbone.stages.2.blocks.1.norm2.weight, encoders.camera.backbone.stages.2.blocks.1.norm2.bias, encoders.camera.backbone.stages.2.blocks.1.ffn.layers.0.0.weight, encoders.camera.backbone.stages.2.blocks.1.ffn.layers.0.0.bias, encoders.camera.backbone.stages.2.blocks.1.ffn.layers.1.weight, encoders.camera.backbone.stages.2.blocks.1.ffn.layers.1.bias, encoders.camera.backbone.stages.2.blocks.2.norm1.weight, encoders.camera.backbone.stages.2.blocks.2.norm1.bias, encoders.camera.backbone.stages.2.blocks.2.attn.w_msa.relative_position_bias_table, encoders.camera.backbone.stages.2.blocks.2.attn.w_msa.relative_position_index, encoders.camera.backbone.stages.2.blocks.2.attn.w_msa.qkv.weight, encoders.camera.backbone.stages.2.blocks.2.attn.w_msa.qkv.bias, encoders.camera.backbone.stages.2.blocks.2.attn.w_msa.proj.weight, encoders.camera.backbone.stages.2.blocks.2.attn.w_msa.proj.bias, encoders.camera.backbone.stages.2.blocks.2.norm2.weight, encoders.camera.backbone.stages.2.blocks.2.norm2.bias, encoders.camera.backbone.stages.2.blocks.2.ffn.layers.0.0.weight, encoders.camera.backbone.stages.2.blocks.2.ffn.layers.0.0.bias, encoders.camera.backbone.stages.2.blocks.2.ffn.layers.1.weight, encoders.camera.backbone.stages.2.blocks.2.ffn.layers.1.bias, encoders.camera.backbone.stages.2.blocks.3.norm1.weight, encoders.camera.backbone.stages.2.blocks.3.norm1.bias, encoders.camera.backbone.stages.2.blocks.3.attn.w_msa.relative_position_bias_table, encoders.camera.backbone.stages.2.blocks.3.attn.w_msa.relative_position_index, encoders.camera.backbone.stages.2.blocks.3.attn.w_msa.qkv.weight, encoders.camera.backbone.stages.2.blocks.3.attn.w_msa.qkv.bias, encoders.camera.backbone.stages.2.blocks.3.attn.w_msa.proj.weight, encoders.camera.backbone.stages.2.blocks.3.attn.w_msa.proj.bias, encoders.camera.backbone.stages.2.blocks.3.norm2.weight, encoders.camera.backbone.stages.2.blocks.3.norm2.bias, encoders.camera.backbone.stages.2.blocks.3.ffn.layers.0.0.weight, encoders.camera.backbone.stages.2.blocks.3.ffn.layers.0.0.bias, encoders.camera.backbone.stages.2.blocks.3.ffn.layers.1.weight, encoders.camera.backbone.stages.2.blocks.3.ffn.layers.1.bias, encoders.camera.backbone.stages.2.blocks.4.norm1.weight, encoders.camera.backbone.stages.2.blocks.4.norm1.bias, encoders.camera.backbone.stages.2.blocks.4.attn.w_msa.relative_position_bias_table, encoders.camera.backbone.stages.2.blocks.4.attn.w_msa.relative_position_index, encoders.camera.backbone.stages.2.blocks.4.attn.w_msa.qkv.weight, encoders.camera.backbone.stages.2.blocks.4.attn.w_msa.qkv.bias, encoders.camera.backbone.stages.2.blocks.4.attn.w_msa.proj.weight, encoders.camera.backbone.stages.2.blocks.4.attn.w_msa.proj.bias, encoders.camera.backbone.stages.2.blocks.4.norm2.weight, encoders.camera.backbone.stages.2.blocks.4.norm2.bias, encoders.camera.backbone.stages.2.blocks.4.ffn.layers.0.0.weight, encoders.camera.backbone.stages.2.blocks.4.ffn.layers.0.0.bias, encoders.camera.backbone.stages.2.blocks.4.ffn.layers.1.weight, encoders.camera.backbone.stages.2.blocks.4.ffn.layers.1.bias, encoders.camera.backbone.stages.2.blocks.5.norm1.weight, encoders.camera.backbone.stages.2.blocks.5.norm1.bias, encoders.camera.backbone.stages.2.blocks.5.attn.w_msa.relative_position_bias_table, encoders.camera.backbone.stages.2.blocks.5.attn.w_msa.relative_position_index, encoders.camera.backbone.stages.2.blocks.5.attn.w_msa.qkv.weight, encoders.camera.backbone.stages.2.blocks.5.attn.w_msa.qkv.bias, encoders.camera.backbone.stages.2.blocks.5.attn.w_msa.proj.weight, encoders.camera.backbone.stages.2.blocks.5.attn.w_msa.proj.bias, encoders.camera.backbone.stages.2.blocks.5.norm2.weight, encoders.camera.backbone.stages.2.blocks.5.norm2.bias, encoders.camera.backbone.stages.2.blocks.5.ffn.layers.0.0.weight, encoders.camera.backbone.stages.2.blocks.5.ffn.layers.0.0.bias, encoders.camera.backbone.stages.2.blocks.5.ffn.layers.1.weight, encoders.camera.backbone.stages.2.blocks.5.ffn.layers.1.bias, encoders.camera.backbone.stages.2.downsample.norm.weight, encoders.camera.backbone.stages.2.downsample.norm.bias, encoders.camera.backbone.stages.2.downsample.reduction.weight, encoders.camera.backbone.stages.3.blocks.0.norm1.weight, encoders.camera.backbone.stages.3.blocks.0.norm1.bias, encoders.camera.backbone.stages.3.blocks.0.attn.w_msa.relative_position_bias_table, encoders.camera.backbone.stages.3.blocks.0.attn.w_msa.relative_position_index, encoders.camera.backbone.stages.3.blocks.0.attn.w_msa.qkv.weight, encoders.camera.backbone.stages.3.blocks.0.attn.w_msa.qkv.bias, encoders.camera.backbone.stages.3.blocks.0.attn.w_msa.proj.weight, encoders.camera.backbone.stages.3.blocks.0.attn.w_msa.proj.bias, encoders.camera.backbone.stages.3.blocks.0.norm2.weight, encoders.camera.backbone.stages.3.blocks.0.norm2.bias, encoders.camera.backbone.stages.3.blocks.0.ffn.layers.0.0.weight, encoders.camera.backbone.stages.3.blocks.0.ffn.layers.0.0.bias, encoders.camera.backbone.stages.3.blocks.0.ffn.layers.1.weight, encoders.camera.backbone.stages.3.blocks.0.ffn.layers.1.bias, encoders.camera.backbone.stages.3.blocks.1.norm1.weight, encoders.camera.backbone.stages.3.blocks.1.norm1.bias, encoders.camera.backbone.stages.3.blocks.1.attn.w_msa.relative_position_bias_table, encoders.camera.backbone.stages.3.blocks.1.attn.w_msa.relative_position_index, encoders.camera.backbone.stages.3.blocks.1.attn.w_msa.qkv.weight, encoders.camera.backbone.stages.3.blocks.1.attn.w_msa.qkv.bias, encoders.camera.backbone.stages.3.blocks.1.attn.w_msa.proj.weight, encoders.camera.backbone.stages.3.blocks.1.attn.w_msa.proj.bias, encoders.camera.backbone.stages.3.blocks.1.norm2.weight, encoders.camera.backbone.stages.3.blocks.1.norm2.bias, encoders.camera.backbone.stages.3.blocks.1.ffn.layers.0.0.weight, encoders.camera.backbone.stages.3.blocks.1.ffn.layers.0.0.bias, encoders.camera.backbone.stages.3.blocks.1.ffn.layers.1.weight, encoders.camera.backbone.stages.3.blocks.1.ffn.layers.1.bias, encoders.camera.backbone.norm1.weight, encoders.camera.backbone.norm1.bias, encoders.camera.backbone.norm2.weight, encoders.camera.backbone.norm2.bias, encoders.camera.backbone.norm3.weight, encoders.camera.backbone.norm3.bias, encoders.camera.neck.lateral_convs.0.conv.weight, encoders.camera.neck.lateral_convs.0.bn.weight, encoders.camera.neck.lateral_convs.0.bn.bias, encoders.camera.neck.lateral_convs.0.bn.running_mean, encoders.camera.neck.lateral_convs.0.bn.running_var, encoders.camera.neck.lateral_convs.1.conv.weight, encoders.camera.neck.lateral_convs.1.bn.weight, encoders.camera.neck.lateral_convs.1.bn.bias, encoders.camera.neck.lateral_convs.1.bn.running_mean, encoders.camera.neck.lateral_convs.1.bn.running_var, encoders.camera.neck.fpn_convs.0.conv.weight, encoders.camera.neck.fpn_convs.0.bn.weight, encoders.camera.neck.fpn_convs.0.bn.bias, encoders.camera.neck.fpn_convs.0.bn.running_mean, encoders.camera.neck.fpn_convs.0.bn.running_var, encoders.camera.neck.fpn_convs.1.conv.weight, encoders.camera.neck.fpn_convs.1.bn.weight, encoders.camera.neck.fpn_convs.1.bn.bias, encoders.camera.neck.fpn_convs.1.bn.running_mean, encoders.camera.neck.fpn_convs.1.bn.running_var, encoders.camera.vtransform.dx, encoders.camera.vtransform.bx, encoders.camera.vtransform.nx, encoders.camera.vtransform.frustum, encoders.camera.vtransform.dtransform.0.weight, encoders.camera.vtransform.dtransform.0.bias, encoders.camera.vtransform.dtransform.1.weight, encoders.camera.vtransform.dtransform.1.bias, encoders.camera.vtransform.dtransform.1.running_mean, encoders.camera.vtransform.dtransform.1.running_var, encoders.camera.vtransform.dtransform.3.weight, encoders.camera.vtransform.dtransform.3.bias, encoders.camera.vtransform.dtransform.4.weight, encoders.camera.vtransform.dtransform.4.bias, encoders.camera.vtransform.dtransform.4.running_mean, encoders.camera.vtransform.dtransform.4.running_var, encoders.camera.vtransform.dtransform.6.weight, encoders.camera.vtransform.dtransform.6.bias, encoders.camera.vtransform.dtransform.7.weight, encoders.camera.vtransform.dtransform.7.bias, encoders.camera.vtransform.dtransform.7.running_mean, encoders.camera.vtransform.dtransform.7.running_var, encoders.camera.vtransform.depthnet.0.weight, encoders.camera.vtransform.depthnet.0.bias, encoders.camera.vtransform.depthnet.1.weight, encoders.camera.vtransform.depthnet.1.bias, encoders.camera.vtransform.depthnet.1.running_mean, encoders.camera.vtransform.depthnet.1.running_var, encoders.camera.vtransform.depthnet.3.weight, encoders.camera.vtransform.depthnet.3.bias, encoders.camera.vtransform.depthnet.4.weight, encoders.camera.vtransform.depthnet.4.bias, encoders.camera.vtransform.depthnet.4.running_mean, encoders.camera.vtransform.depthnet.4.running_var, encoders.camera.vtransform.depthnet.6.weight, encoders.camera.vtransform.depthnet.6.bias, encoders.camera.vtransform.downsample.0.weight, encoders.camera.vtransform.downsample.1.weight, encoders.camera.vtransform.downsample.1.bias, encoders.camera.vtransform.downsample.1.running_mean, encoders.camera.vtransform.downsample.1.running_var, encoders.camera.vtransform.downsample.3.weight, encoders.camera.vtransform.downsample.4.weight, encoders.camera.vtransform.downsample.4.bias, encoders.camera.vtransform.downsample.4.running_mean, encoders.camera.vtransform.downsample.4.running_var, encoders.camera.vtransform.downsample.6.weight, encoders.camera.vtransform.downsample.7.weight, encoders.camera.vtransform.downsample.7.bias, encoders.camera.vtransform.downsample.7.running_mean, encoders.camera.vtransform.downsample.7.running_var, encoders.infra.backbone.patch_embed.projection.weight, encoders.infra.backbone.patch_embed.projection.bias, encoders.infra.backbone.patch_embed.norm.weight, encoders.infra.backbone.patch_embed.norm.bias, encoders.infra.backbone.stages.0.blocks.0.norm1.weight, encoders.infra.backbone.stages.0.blocks.0.norm1.bias, encoders.infra.backbone.stages.0.blocks.0.attn.w_msa.relative_position_bias_table, encoders.infra.backbone.stages.0.blocks.0.attn.w_msa.relative_position_index, encoders.infra.backbone.stages.0.blocks.0.attn.w_msa.qkv.weight, encoders.infra.backbone.stages.0.blocks.0.attn.w_msa.qkv.bias, encoders.infra.backbone.stages.0.blocks.0.attn.w_msa.proj.weight, encoders.infra.backbone.stages.0.blocks.0.attn.w_msa.proj.bias, encoders.infra.backbone.stages.0.blocks.0.norm2.weight, encoders.infra.backbone.stages.0.blocks.0.norm2.bias, encoders.infra.backbone.stages.0.blocks.0.ffn.layers.0.0.weight, encoders.infra.backbone.stages.0.blocks.0.ffn.layers.0.0.bias, encoders.infra.backbone.stages.0.blocks.0.ffn.layers.1.weight, encoders.infra.backbone.stages.0.blocks.0.ffn.layers.1.bias, encoders.infra.backbone.stages.0.blocks.1.norm1.weight, encoders.infra.backbone.stages.0.blocks.1.norm1.bias, encoders.infra.backbone.stages.0.blocks.1.attn.w_msa.relative_position_bias_table, encoders.infra.backbone.stages.0.blocks.1.attn.w_msa.relative_position_index, encoders.infra.backbone.stages.0.blocks.1.attn.w_msa.qkv.weight, encoders.infra.backbone.stages.0.blocks.1.attn.w_msa.qkv.bias, encoders.infra.backbone.stages.0.blocks.1.attn.w_msa.proj.weight, encoders.infra.backbone.stages.0.blocks.1.attn.w_msa.proj.bias, encoders.infra.backbone.stages.0.blocks.1.norm2.weight, encoders.infra.backbone.stages.0.blocks.1.norm2.bias, encoders.infra.backbone.stages.0.blocks.1.ffn.layers.0.0.weight, encoders.infra.backbone.stages.0.blocks.1.ffn.layers.0.0.bias, encoders.infra.backbone.stages.0.blocks.1.ffn.layers.1.weight, encoders.infra.backbone.stages.0.blocks.1.ffn.layers.1.bias, encoders.infra.backbone.stages.0.downsample.norm.weight, encoders.infra.backbone.stages.0.downsample.norm.bias, encoders.infra.backbone.stages.0.downsample.reduction.weight, encoders.infra.backbone.stages.1.blocks.0.norm1.weight, encoders.infra.backbone.stages.1.blocks.0.norm1.bias, encoders.infra.backbone.stages.1.blocks.0.attn.w_msa.relative_position_bias_table, encoders.infra.backbone.stages.1.blocks.0.attn.w_msa.relative_position_index, encoders.infra.backbone.stages.1.blocks.0.attn.w_msa.qkv.weight, encoders.infra.backbone.stages.1.blocks.0.attn.w_msa.qkv.bias, encoders.infra.backbone.stages.1.blocks.0.attn.w_msa.proj.weight, encoders.infra.backbone.stages.1.blocks.0.attn.w_msa.proj.bias, encoders.infra.backbone.stages.1.blocks.0.norm2.weight, encoders.infra.backbone.stages.1.blocks.0.norm2.bias, encoders.infra.backbone.stages.1.blocks.0.ffn.layers.0.0.weight, encoders.infra.backbone.stages.1.blocks.0.ffn.layers.0.0.bias, encoders.infra.backbone.stages.1.blocks.0.ffn.layers.1.weight, encoders.infra.backbone.stages.1.blocks.0.ffn.layers.1.bias, encoders.infra.backbone.stages.1.blocks.1.norm1.weight, encoders.infra.backbone.stages.1.blocks.1.norm1.bias, encoders.infra.backbone.stages.1.blocks.1.attn.w_msa.relative_position_bias_table, encoders.infra.backbone.stages.1.blocks.1.attn.w_msa.relative_position_index, encoders.infra.backbone.stages.1.blocks.1.attn.w_msa.qkv.weight, encoders.infra.backbone.stages.1.blocks.1.attn.w_msa.qkv.bias, encoders.infra.backbone.stages.1.blocks.1.attn.w_msa.proj.weight, encoders.infra.backbone.stages.1.blocks.1.attn.w_msa.proj.bias, encoders.infra.backbone.stages.1.blocks.1.norm2.weight, encoders.infra.backbone.stages.1.blocks.1.norm2.bias, encoders.infra.backbone.stages.1.blocks.1.ffn.layers.0.0.weight, encoders.infra.backbone.stages.1.blocks.1.ffn.layers.0.0.bias, encoders.infra.backbone.stages.1.blocks.1.ffn.layers.1.weight, encoders.infra.backbone.stages.1.blocks.1.ffn.layers.1.bias, encoders.infra.backbone.stages.1.downsample.norm.weight, encoders.infra.backbone.stages.1.downsample.norm.bias, encoders.infra.backbone.stages.1.downsample.reduction.weight, encoders.infra.backbone.stages.2.blocks.0.norm1.weight, encoders.infra.backbone.stages.2.blocks.0.norm1.bias, encoders.infra.backbone.stages.2.blocks.0.attn.w_msa.relative_position_bias_table, encoders.infra.backbone.stages.2.blocks.0.attn.w_msa.relative_position_index, encoders.infra.backbone.stages.2.blocks.0.attn.w_msa.qkv.weight, encoders.infra.backbone.stages.2.blocks.0.attn.w_msa.qkv.bias, encoders.infra.backbone.stages.2.blocks.0.attn.w_msa.proj.weight, encoders.infra.backbone.stages.2.blocks.0.attn.w_msa.proj.bias, encoders.infra.backbone.stages.2.blocks.0.norm2.weight, encoders.infra.backbone.stages.2.blocks.0.norm2.bias, encoders.infra.backbone.stages.2.blocks.0.ffn.layers.0.0.weight, encoders.infra.backbone.stages.2.blocks.0.ffn.layers.0.0.bias, encoders.infra.backbone.stages.2.blocks.0.ffn.layers.1.weight, encoders.infra.backbone.stages.2.blocks.0.ffn.layers.1.bias, encoders.infra.backbone.stages.2.blocks.1.norm1.weight, encoders.infra.backbone.stages.2.blocks.1.norm1.bias, encoders.infra.backbone.stages.2.blocks.1.attn.w_msa.relative_position_bias_table, encoders.infra.backbone.stages.2.blocks.1.attn.w_msa.relative_position_index, encoders.infra.backbone.stages.2.blocks.1.attn.w_msa.qkv.weight, encoders.infra.backbone.stages.2.blocks.1.attn.w_msa.qkv.bias, encoders.infra.backbone.stages.2.blocks.1.attn.w_msa.proj.weight, encoders.infra.backbone.stages.2.blocks.1.attn.w_msa.proj.bias, encoders.infra.backbone.stages.2.blocks.1.norm2.weight, encoders.infra.backbone.stages.2.blocks.1.norm2.bias, encoders.infra.backbone.stages.2.blocks.1.ffn.layers.0.0.weight, encoders.infra.backbone.stages.2.blocks.1.ffn.layers.0.0.bias, encoders.infra.backbone.stages.2.blocks.1.ffn.layers.1.weight, encoders.infra.backbone.stages.2.blocks.1.ffn.layers.1.bias, encoders.infra.backbone.stages.2.blocks.2.norm1.weight, encoders.infra.backbone.stages.2.blocks.2.norm1.bias, encoders.infra.backbone.stages.2.blocks.2.attn.w_msa.relative_position_bias_table, encoders.infra.backbone.stages.2.blocks.2.attn.w_msa.relative_position_index, encoders.infra.backbone.stages.2.blocks.2.attn.w_msa.qkv.weight, encoders.infra.backbone.stages.2.blocks.2.attn.w_msa.qkv.bias, encoders.infra.backbone.stages.2.blocks.2.attn.w_msa.proj.weight, encoders.infra.backbone.stages.2.blocks.2.attn.w_msa.proj.bias, encoders.infra.backbone.stages.2.blocks.2.norm2.weight, encoders.infra.backbone.stages.2.blocks.2.norm2.bias, encoders.infra.backbone.stages.2.blocks.2.ffn.layers.0.0.weight, encoders.infra.backbone.stages.2.blocks.2.ffn.layers.0.0.bias, encoders.infra.backbone.stages.2.blocks.2.ffn.layers.1.weight, encoders.infra.backbone.stages.2.blocks.2.ffn.layers.1.bias, encoders.infra.backbone.stages.2.blocks.3.norm1.weight, encoders.infra.backbone.stages.2.blocks.3.norm1.bias, encoders.infra.backbone.stages.2.blocks.3.attn.w_msa.relative_position_bias_table, encoders.infra.backbone.stages.2.blocks.3.attn.w_msa.relative_position_index, encoders.infra.backbone.stages.2.blocks.3.attn.w_msa.qkv.weight, encoders.infra.backbone.stages.2.blocks.3.attn.w_msa.qkv.bias, encoders.infra.backbone.stages.2.blocks.3.attn.w_msa.proj.weight, encoders.infra.backbone.stages.2.blocks.3.attn.w_msa.proj.bias, encoders.infra.backbone.stages.2.blocks.3.norm2.weight, encoders.infra.backbone.stages.2.blocks.3.norm2.bias, encoders.infra.backbone.stages.2.blocks.3.ffn.layers.0.0.weight, encoders.infra.backbone.stages.2.blocks.3.ffn.layers.0.0.bias, encoders.infra.backbone.stages.2.blocks.3.ffn.layers.1.weight, encoders.infra.backbone.stages.2.blocks.3.ffn.layers.1.bias, encoders.infra.backbone.stages.2.blocks.4.norm1.weight, encoders.infra.backbone.stages.2.blocks.4.norm1.bias, encoders.infra.backbone.stages.2.blocks.4.attn.w_msa.relative_position_bias_table, encoders.infra.backbone.stages.2.blocks.4.attn.w_msa.relative_position_index, encoders.infra.backbone.stages.2.blocks.4.attn.w_msa.qkv.weight, encoders.infra.backbone.stages.2.blocks.4.attn.w_msa.qkv.bias, encoders.infra.backbone.stages.2.blocks.4.attn.w_msa.proj.weight, encoders.infra.backbone.stages.2.blocks.4.attn.w_msa.proj.bias, encoders.infra.backbone.stages.2.blocks.4.norm2.weight, encoders.infra.backbone.stages.2.blocks.4.norm2.bias, encoders.infra.backbone.stages.2.blocks.4.ffn.layers.0.0.weight, encoders.infra.backbone.stages.2.blocks.4.ffn.layers.0.0.bias, encoders.infra.backbone.stages.2.blocks.4.ffn.layers.1.weight, encoders.infra.backbone.stages.2.blocks.4.ffn.layers.1.bias, encoders.infra.backbone.stages.2.blocks.5.norm1.weight, encoders.infra.backbone.stages.2.blocks.5.norm1.bias, encoders.infra.backbone.stages.2.blocks.5.attn.w_msa.relative_position_bias_table, encoders.infra.backbone.stages.2.blocks.5.attn.w_msa.relative_position_index, encoders.infra.backbone.stages.2.blocks.5.attn.w_msa.qkv.weight, encoders.infra.backbone.stages.2.blocks.5.attn.w_msa.qkv.bias, encoders.infra.backbone.stages.2.blocks.5.attn.w_msa.proj.weight, encoders.infra.backbone.stages.2.blocks.5.attn.w_msa.proj.bias, encoders.infra.backbone.stages.2.blocks.5.norm2.weight, encoders.infra.backbone.stages.2.blocks.5.norm2.bias, encoders.infra.backbone.stages.2.blocks.5.ffn.layers.0.0.weight, encoders.infra.backbone.stages.2.blocks.5.ffn.layers.0.0.bias, encoders.infra.backbone.stages.2.blocks.5.ffn.layers.1.weight, encoders.infra.backbone.stages.2.blocks.5.ffn.layers.1.bias, encoders.infra.backbone.stages.2.downsample.norm.weight, encoders.infra.backbone.stages.2.downsample.norm.bias, encoders.infra.backbone.stages.2.downsample.reduction.weight, encoders.infra.backbone.stages.3.blocks.0.norm1.weight, encoders.infra.backbone.stages.3.blocks.0.norm1.bias, encoders.infra.backbone.stages.3.blocks.0.attn.w_msa.relative_position_bias_table, encoders.infra.backbone.stages.3.blocks.0.attn.w_msa.relative_position_index, encoders.infra.backbone.stages.3.blocks.0.attn.w_msa.qkv.weight, encoders.infra.backbone.stages.3.blocks.0.attn.w_msa.qkv.bias, encoders.infra.backbone.stages.3.blocks.0.attn.w_msa.proj.weight, encoders.infra.backbone.stages.3.blocks.0.attn.w_msa.proj.bias, encoders.infra.backbone.stages.3.blocks.0.norm2.weight, encoders.infra.backbone.stages.3.blocks.0.norm2.bias, encoders.infra.backbone.stages.3.blocks.0.ffn.layers.0.0.weight, encoders.infra.backbone.stages.3.blocks.0.ffn.layers.0.0.bias, encoders.infra.backbone.stages.3.blocks.0.ffn.layers.1.weight, encoders.infra.backbone.stages.3.blocks.0.ffn.layers.1.bias, encoders.infra.backbone.stages.3.blocks.1.norm1.weight, encoders.infra.backbone.stages.3.blocks.1.norm1.bias, encoders.infra.backbone.stages.3.blocks.1.attn.w_msa.relative_position_bias_table, encoders.infra.backbone.stages.3.blocks.1.attn.w_msa.relative_position_index, encoders.infra.backbone.stages.3.blocks.1.attn.w_msa.qkv.weight, encoders.infra.backbone.stages.3.blocks.1.attn.w_msa.qkv.bias, encoders.infra.backbone.stages.3.blocks.1.attn.w_msa.proj.weight, encoders.infra.backbone.stages.3.blocks.1.attn.w_msa.proj.bias, encoders.infra.backbone.stages.3.blocks.1.norm2.weight, encoders.infra.backbone.stages.3.blocks.1.norm2.bias, encoders.infra.backbone.stages.3.blocks.1.ffn.layers.0.0.weight, encoders.infra.backbone.stages.3.blocks.1.ffn.layers.0.0.bias, encoders.infra.backbone.stages.3.blocks.1.ffn.layers.1.weight, encoders.infra.backbone.stages.3.blocks.1.ffn.layers.1.bias, encoders.infra.backbone.norm1.weight, encoders.infra.backbone.norm1.bias, encoders.infra.backbone.norm2.weight, encoders.infra.backbone.norm2.bias, encoders.infra.backbone.norm3.weight, encoders.infra.backbone.norm3.bias, encoders.infra.neck.lateral_convs.0.conv.weight, encoders.infra.neck.lateral_convs.0.bn.weight, encoders.infra.neck.lateral_convs.0.bn.bias, encoders.infra.neck.lateral_convs.0.bn.running_mean, encoders.infra.neck.lateral_convs.0.bn.running_var, encoders.infra.neck.lateral_convs.1.conv.weight, encoders.infra.neck.lateral_convs.1.bn.weight, encoders.infra.neck.lateral_convs.1.bn.bias, encoders.infra.neck.lateral_convs.1.bn.running_mean, encoders.infra.neck.lateral_convs.1.bn.running_var, encoders.infra.neck.fpn_convs.0.conv.weight, encoders.infra.neck.fpn_convs.0.bn.weight, encoders.infra.neck.fpn_convs.0.bn.bias, encoders.infra.neck.fpn_convs.0.bn.running_mean, encoders.infra.neck.fpn_convs.0.bn.running_var, encoders.infra.neck.fpn_convs.1.conv.weight, encoders.infra.neck.fpn_convs.1.bn.weight, encoders.infra.neck.fpn_convs.1.bn.bias, encoders.infra.neck.fpn_convs.1.bn.running_mean, encoders.infra.neck.fpn_convs.1.bn.running_var, encoders.infra.vtransform.dx, encoders.infra.vtransform.bx, encoders.infra.vtransform.nx, encoders.infra.vtransform.frustum, encoders.infra.vtransform.dtransform.0.weight, encoders.infra.vtransform.dtransform.0.bias, encoders.infra.vtransform.dtransform.1.weight, encoders.infra.vtransform.dtransform.1.bias, encoders.infra.vtransform.dtransform.1.running_mean, encoders.infra.vtransform.dtransform.1.running_var, encoders.infra.vtransform.dtransform.3.weight, encoders.infra.vtransform.dtransform.3.bias, encoders.infra.vtransform.dtransform.4.weight, encoders.infra.vtransform.dtransform.4.bias, encoders.infra.vtransform.dtransform.4.running_mean, encoders.infra.vtransform.dtransform.4.running_var, encoders.infra.vtransform.dtransform.6.weight, encoders.infra.vtransform.dtransform.6.bias, encoders.infra.vtransform.dtransform.7.weight, encoders.infra.vtransform.dtransform.7.bias, encoders.infra.vtransform.dtransform.7.running_mean, encoders.infra.vtransform.dtransform.7.running_var, encoders.infra.vtransform.depthnet.0.weight, encoders.infra.vtransform.depthnet.0.bias, encoders.infra.vtransform.depthnet.1.weight, encoders.infra.vtransform.depthnet.1.bias, encoders.infra.vtransform.depthnet.1.running_mean, encoders.infra.vtransform.depthnet.1.running_var, encoders.infra.vtransform.depthnet.3.weight, encoders.infra.vtransform.depthnet.3.bias, encoders.infra.vtransform.depthnet.4.weight, encoders.infra.vtransform.depthnet.4.bias, encoders.infra.vtransform.depthnet.4.running_mean, encoders.infra.vtransform.depthnet.4.running_var, encoders.infra.vtransform.depthnet.6.weight, encoders.infra.vtransform.depthnet.6.bias, encoders.infra.vtransform.downsample.0.weight, encoders.infra.vtransform.downsample.1.weight, encoders.infra.vtransform.downsample.1.bias, encoders.infra.vtransform.downsample.1.running_mean, encoders.infra.vtransform.downsample.1.running_var, encoders.infra.vtransform.downsample.3.weight, encoders.infra.vtransform.downsample.4.weight, encoders.infra.vtransform.downsample.4.bias, encoders.infra.vtransform.downsample.4.running_mean, encoders.infra.vtransform.downsample.4.running_var, encoders.infra.vtransform.downsample.6.weight, encoders.infra.vtransform.downsample.7.weight, encoders.infra.vtransform.downsample.7.bias, encoders.infra.vtransform.downsample.7.running_mean, encoders.infra.vtransform.downsample.7.running_var, fuser.0.weight, fuser.1.weight, fuser.1.bias, fuser.1.running_mean, fuser.1.running_var

2024-09-03 22:15:56,058 - mmdet3d - INFO - Start running, host: jmeng18@sg048, work_dir: /home/jmeng18/bev_fusion/bevfusion-beliv/train_result_infra_long_full
2024-09-03 22:15:56,059 - mmdet3d - INFO - Hooks will be executed in the following order:
before_run:
(VERY_HIGH   ) CosineAnnealingLrUpdaterHook       
(HIGH        ) CyclicMomentumUpdaterHook          
(ABOVE_NORMAL) Fp16OptimizerHook                  
(NORMAL      ) CheckpointHook                     
(NORMAL      ) DistEvalHook                       
(VERY_LOW    ) TextLoggerHook                     
(VERY_LOW    ) TensorboardLoggerHook              
 -------------------- 
before_train_epoch:
(VERY_HIGH   ) CosineAnnealingLrUpdaterHook       
(HIGH        ) CyclicMomentumUpdaterHook          
(NORMAL      ) DistSamplerSeedHook                
(NORMAL      ) DistEvalHook                       
(LOW         ) IterTimerHook                      
(VERY_LOW    ) TextLoggerHook                     
(VERY_LOW    ) TensorboardLoggerHook              
 -------------------- 
before_train_iter:
(VERY_HIGH   ) CosineAnnealingLrUpdaterHook       
(HIGH        ) CyclicMomentumUpdaterHook          
(NORMAL      ) DistEvalHook                       
(LOW         ) IterTimerHook                      
 -------------------- 
after_train_iter:
(ABOVE_NORMAL) Fp16OptimizerHook                  
(NORMAL      ) CheckpointHook                     
(NORMAL      ) DistEvalHook                       
(LOW         ) IterTimerHook                      
(VERY_LOW    ) TextLoggerHook                     
(VERY_LOW    ) TensorboardLoggerHook              
 -------------------- 
after_train_epoch:
(NORMAL      ) CheckpointHook                     
(NORMAL      ) DistEvalHook                       
(VERY_LOW    ) TextLoggerHook                     
(VERY_LOW    ) TensorboardLoggerHook              
 -------------------- 
before_val_epoch:
(NORMAL      ) DistSamplerSeedHook                
(LOW         ) IterTimerHook                      
(VERY_LOW    ) TextLoggerHook                     
(VERY_LOW    ) TensorboardLoggerHook              
 -------------------- 
before_val_iter:
(LOW         ) IterTimerHook                      
 -------------------- 
after_val_iter:
(LOW         ) IterTimerHook                      
 -------------------- 
after_val_epoch:
(VERY_LOW    ) TextLoggerHook                     
(VERY_LOW    ) TensorboardLoggerHook              
 -------------------- 
after_run:
(VERY_LOW    ) TextLoggerHook                     
(VERY_LOW    ) TensorboardLoggerHook              
 -------------------- 
2024-09-03 22:15:56,059 - mmdet3d - INFO - workflow: [('train', 1)], max: 10 epochs
2024-09-03 22:15:56,061 - mmdet3d - INFO - Checkpoints will be saved to /home/jmeng18/bev_fusion/bevfusion-beliv/train_result_infra_long_full by HardDiskBackend.
2024-09-03 22:16:53,307 - mmdet3d - INFO - Epoch [1][50/8000]	lr: 3.987e-05, eta: 1 day, 1:23:10, time: 1.143, data_time: 0.075, memory: 6845, loss/object/loss_heatmap: 161.5095, loss/object/layer_-1_loss_cls: 0.7300, loss/object/layer_-1_loss_bbox: 7.8330, stats/object/matched_ious: 0.0073, loss: 170.0724, grad_norm: nan
2024-09-03 22:17:47,428 - mmdet3d - INFO - Epoch [1][100/8000]	lr: 4.653e-05, eta: 1 day, 0:41:49, time: 1.082, data_time: 0.013, memory: 6846, loss/object/loss_heatmap: 69.9841, loss/object/layer_-1_loss_cls: 0.5353, loss/object/layer_-1_loss_bbox: 4.7608, stats/object/matched_ious: 0.0107, loss: 75.2802, grad_norm: 707.0161
2024-09-03 22:18:41,153 - mmdet3d - INFO - Epoch [1][150/8000]	lr: 5.320e-05, eta: 1 day, 0:23:54, time: 1.074, data_time: 0.014, memory: 6846, loss/object/loss_heatmap: 27.7467, loss/object/layer_-1_loss_cls: 0.4909, loss/object/layer_-1_loss_bbox: 4.2673, stats/object/matched_ious: 0.0131, loss: 32.5049, grad_norm: 354.8006
2024-09-03 22:19:35,906 - mmdet3d - INFO - Epoch [1][200/8000]	lr: 5.987e-05, eta: 1 day, 0:21:20, time: 1.095, data_time: 0.014, memory: 6858, loss/object/loss_heatmap: 9.0068, loss/object/layer_-1_loss_cls: 0.4318, loss/object/layer_-1_loss_bbox: 3.7211, stats/object/matched_ious: 0.0260, loss: 13.1596, grad_norm: 141.5036
2024-09-03 22:20:32,171 - mmdet3d - INFO - Epoch [1][250/8000]	lr: 6.653e-05, eta: 1 day, 0:27:29, time: 1.125, data_time: 0.037, memory: 6868, loss/object/loss_heatmap: 3.1762, loss/object/layer_-1_loss_cls: 0.3053, loss/object/layer_-1_loss_bbox: 2.7495, stats/object/matched_ious: 0.0663, loss: 6.2311, grad_norm: 51.4834
2024-09-03 22:21:59,935 - mmdet3d - INFO - Epoch [1][300/8000]	lr: 7.320e-05, eta: 1 day, 2:50:43, time: 1.755, data_time: 0.642, memory: 6868, loss/object/loss_heatmap: 2.1103, loss/object/layer_-1_loss_cls: 0.2699, loss/object/layer_-1_loss_bbox: 2.6283, stats/object/matched_ious: 0.0893, loss: 5.0084, grad_norm: 33.4420
2024-09-03 22:23:26,564 - mmdet3d - INFO - Epoch [1][350/8000]	lr: 7.987e-05, eta: 1 day, 4:28:19, time: 1.733, data_time: 0.570, memory: 6868, loss/object/loss_heatmap: 1.6388, loss/object/layer_-1_loss_cls: 0.2227, loss/object/layer_-1_loss_bbox: 1.9721, stats/object/matched_ious: 0.1292, loss: 3.8337, grad_norm: 20.2398
2024-09-03 22:24:48,967 - mmdet3d - INFO - Epoch [1][400/8000]	lr: 8.653e-05, eta: 1 day, 5:27:08, time: 1.648, data_time: 0.513, memory: 6868, loss/object/loss_heatmap: 1.5238, loss/object/layer_-1_loss_cls: 0.1996, loss/object/layer_-1_loss_bbox: 2.0980, stats/object/matched_ious: 0.1425, loss: 3.8214, grad_norm: 19.9545
2024-09-03 22:26:20,984 - mmdet3d - INFO - Epoch [1][450/8000]	lr: 9.320e-05, eta: 1 day, 6:40:54, time: 1.840, data_time: 0.667, memory: 6868, loss/object/loss_heatmap: 1.4388, loss/object/layer_-1_loss_cls: 0.1728, loss/object/layer_-1_loss_bbox: 2.1709, stats/object/matched_ious: 0.1465, loss: 3.7825, grad_norm: 18.8515
2024-09-03 22:28:09,653 - mmdet3d - INFO - Epoch [1][500/8000]	lr: 9.987e-05, eta: 1 day, 8:23:45, time: 2.173, data_time: 1.026, memory: 6870, loss/object/loss_heatmap: 1.3015, loss/object/layer_-1_loss_cls: 0.1494, loss/object/layer_-1_loss_bbox: 2.0618, stats/object/matched_ious: 0.1696, loss: 3.5127, grad_norm: 20.9296
2024-09-03 22:29:57,923 - mmdet3d - INFO - Epoch [1][550/8000]	lr: 1.000e-04, eta: 1 day, 9:46:36, time: 2.165, data_time: 1.019, memory: 6870, loss/object/loss_heatmap: 1.2946, loss/object/layer_-1_loss_cls: 0.1541, loss/object/layer_-1_loss_bbox: 1.9893, stats/object/matched_ious: 0.1634, loss: 3.4380, grad_norm: 19.2202
2024-09-03 22:31:40,571 - mmdet3d - INFO - Epoch [1][600/8000]	lr: 1.000e-04, eta: 1 day, 10:42:56, time: 2.053, data_time: 0.903, memory: 6870, loss/object/loss_heatmap: 1.2076, loss/object/layer_-1_loss_cls: 0.1267, loss/object/layer_-1_loss_bbox: 1.9069, stats/object/matched_ious: 0.1745, loss: 3.2412, grad_norm: 12.6974
2024-09-03 22:33:16,012 - mmdet3d - INFO - Epoch [1][650/8000]	lr: 1.000e-04, eta: 1 day, 11:15:41, time: 1.909, data_time: 0.757, memory: 6870, loss/object/loss_heatmap: 1.2110, loss/object/layer_-1_loss_cls: 0.1243, loss/object/layer_-1_loss_bbox: 1.9567, stats/object/matched_ious: 0.1806, loss: 3.2921, grad_norm: 12.1549
2024-09-03 22:34:52,545 - mmdet3d - INFO - Epoch [1][700/8000]	lr: 1.000e-04, eta: 1 day, 11:45:35, time: 1.931, data_time: 0.807, memory: 6870, loss/object/loss_heatmap: 1.1902, loss/object/layer_-1_loss_cls: 0.1388, loss/object/layer_-1_loss_bbox: 1.7598, stats/object/matched_ious: 0.1959, loss: 3.0888, grad_norm: 12.6067
2024-09-03 22:36:25,587 - mmdet3d - INFO - Epoch [1][750/8000]	lr: 1.000e-04, eta: 1 day, 12:05:08, time: 1.861, data_time: 0.754, memory: 6870, loss/object/loss_heatmap: 1.1027, loss/object/layer_-1_loss_cls: 0.1184, loss/object/layer_-1_loss_bbox: 1.8311, stats/object/matched_ious: 0.1921, loss: 3.0521, grad_norm: 11.5202
2024-09-03 22:38:05,974 - mmdet3d - INFO - Epoch [1][800/8000]	lr: 1.000e-04, eta: 1 day, 12:34:10, time: 2.008, data_time: 0.884, memory: 6870, loss/object/loss_heatmap: 1.1596, loss/object/layer_-1_loss_cls: 0.1230, loss/object/layer_-1_loss_bbox: 1.8286, stats/object/matched_ious: 0.1969, loss: 3.1111, grad_norm: 14.7200
2024-09-03 22:39:46,997 - mmdet3d - INFO - Epoch [1][850/8000]	lr: 1.000e-04, eta: 1 day, 13:00:35, time: 2.020, data_time: 0.893, memory: 6870, loss/object/loss_heatmap: 1.1470, loss/object/layer_-1_loss_cls: 0.1158, loss/object/layer_-1_loss_bbox: 2.0587, stats/object/matched_ious: 0.1943, loss: 3.3215, grad_norm: 13.4890
2024-09-03 22:41:22,307 - mmdet3d - INFO - Epoch [1][900/8000]	lr: 1.000e-04, eta: 1 day, 13:15:30, time: 1.906, data_time: 0.804, memory: 6882, loss/object/loss_heatmap: 1.1024, loss/object/layer_-1_loss_cls: 0.1114, loss/object/layer_-1_loss_bbox: 1.8449, stats/object/matched_ious: 0.1899, loss: 3.0587, grad_norm: 13.2801
2024-09-03 22:42:46,762 - mmdet3d - INFO - Epoch [1][950/8000]	lr: 1.000e-04, eta: 1 day, 13:13:38, time: 1.689, data_time: 0.590, memory: 6882, loss/object/loss_heatmap: 1.1063, loss/object/layer_-1_loss_cls: 0.1189, loss/object/layer_-1_loss_bbox: 1.7755, stats/object/matched_ious: 0.1974, loss: 3.0007, grad_norm: 12.7045
2024-09-03 22:43:59,804 - mmdet3d - INFO - Epoch [1][1000/8000]	lr: 1.000e-04, eta: 1 day, 12:56:46, time: 1.461, data_time: 0.372, memory: 6882, loss/object/loss_heatmap: 1.0765, loss/object/layer_-1_loss_cls: 0.1101, loss/object/layer_-1_loss_bbox: 1.7826, stats/object/matched_ious: 0.1825, loss: 2.9692, grad_norm: 13.9703
2024-09-03 22:45:32,256 - mmdet3d - INFO - Epoch [1][1050/8000]	lr: 1.000e-04, eta: 1 day, 13:05:44, time: 1.849, data_time: 0.719, memory: 6882, loss/object/loss_heatmap: 1.0873, loss/object/layer_-1_loss_cls: 0.1036, loss/object/layer_-1_loss_bbox: 1.8761, stats/object/matched_ious: 0.1992, loss: 3.0670, grad_norm: 10.6384
2024-09-03 22:47:04,404 - mmdet3d - INFO - Epoch [1][1100/8000]	lr: 1.000e-04, eta: 1 day, 13:13:23, time: 1.843, data_time: 0.773, memory: 6882, loss/object/loss_heatmap: 1.1117, loss/object/layer_-1_loss_cls: 0.1189, loss/object/layer_-1_loss_bbox: 1.9410, stats/object/matched_ious: 0.1966, loss: 3.1716, grad_norm: 11.4665
2024-09-03 22:48:14,196 - mmdet3d - INFO - Epoch [1][1150/8000]	lr: 1.000e-04, eta: 1 day, 12:54:40, time: 1.396, data_time: 0.326, memory: 6882, loss/object/loss_heatmap: 1.0131, loss/object/layer_-1_loss_cls: 0.0985, loss/object/layer_-1_loss_bbox: 1.7769, stats/object/matched_ious: 0.2085, loss: 2.8885, grad_norm: 9.4269
2024-09-03 22:49:24,277 - mmdet3d - INFO - Epoch [1][1200/8000]	lr: 1.000e-04, eta: 1 day, 12:37:45, time: 1.402, data_time: 0.331, memory: 6882, loss/object/loss_heatmap: 1.0394, loss/object/layer_-1_loss_cls: 0.0996, loss/object/layer_-1_loss_bbox: 1.8261, stats/object/matched_ious: 0.2153, loss: 2.9651, grad_norm: 9.8978
2024-09-03 22:50:33,440 - mmdet3d - INFO - Epoch [1][1250/8000]	lr: 1.000e-04, eta: 1 day, 12:21:07, time: 1.383, data_time: 0.292, memory: 6882, loss/object/loss_heatmap: 1.0200, loss/object/layer_-1_loss_cls: 0.0988, loss/object/layer_-1_loss_bbox: 1.8118, stats/object/matched_ious: 0.2297, loss: 2.9305, grad_norm: 9.7272
2024-09-03 22:51:43,770 - mmdet3d - INFO - Epoch [1][1300/8000]	lr: 1.000e-04, eta: 1 day, 12:06:52, time: 1.407, data_time: 0.309, memory: 6882, loss/object/loss_heatmap: 1.0605, loss/object/layer_-1_loss_cls: 0.0985, loss/object/layer_-1_loss_bbox: 1.8694, stats/object/matched_ious: 0.2250, loss: 3.0284, grad_norm: 8.7939
2024-09-03 22:52:55,281 - mmdet3d - INFO - Epoch [1][1350/8000]	lr: 1.000e-04, eta: 1 day, 11:54:43, time: 1.430, data_time: 0.356, memory: 6882, loss/object/loss_heatmap: 1.0591, loss/object/layer_-1_loss_cls: 0.1058, loss/object/layer_-1_loss_bbox: 1.8138, stats/object/matched_ious: 0.2452, loss: 2.9786, grad_norm: 8.7488
2024-09-03 22:54:11,296 - mmdet3d - INFO - Epoch [1][1400/8000]	lr: 1.000e-04, eta: 1 day, 11:47:34, time: 1.520, data_time: 0.421, memory: 6882, loss/object/loss_heatmap: 0.9790, loss/object/layer_-1_loss_cls: 0.0956, loss/object/layer_-1_loss_bbox: 1.6451, stats/object/matched_ious: 0.2343, loss: 2.7198, grad_norm: 7.7830
2024-09-03 22:55:31,311 - mmdet3d - INFO - Epoch [1][1450/8000]	lr: 1.000e-04, eta: 1 day, 11:44:26, time: 1.600, data_time: 0.509, memory: 6889, loss/object/loss_heatmap: 0.9999, loss/object/layer_-1_loss_cls: 0.0995, loss/object/layer_-1_loss_bbox: 1.7183, stats/object/matched_ious: 0.2499, loss: 2.8178, grad_norm: 8.9955
2024-09-03 22:56:42,751 - mmdet3d - INFO - Epoch [1][1500/8000]	lr: 1.000e-04, eta: 1 day, 11:33:57, time: 1.429, data_time: 0.355, memory: 6889, loss/object/loss_heatmap: 0.9927, loss/object/layer_-1_loss_cls: 0.0993, loss/object/layer_-1_loss_bbox: 1.7347, stats/object/matched_ious: 0.2394, loss: 2.8267, grad_norm: 8.9588
2024-09-03 22:57:58,516 - mmdet3d - INFO - Epoch [1][1550/8000]	lr: 1.000e-04, eta: 1 day, 11:27:42, time: 1.515, data_time: 0.434, memory: 6889, loss/object/loss_heatmap: 1.0252, loss/object/layer_-1_loss_cls: 0.1022, loss/object/layer_-1_loss_bbox: 1.6973, stats/object/matched_ious: 0.2528, loss: 2.8247, grad_norm: 9.4816
2024-09-03 22:59:14,824 - mmdet3d - INFO - Epoch [1][1600/8000]	lr: 1.000e-04, eta: 1 day, 11:22:13, time: 1.526, data_time: 0.460, memory: 6889, loss/object/loss_heatmap: 1.0033, loss/object/layer_-1_loss_cls: 0.0978, loss/object/layer_-1_loss_bbox: 1.7986, stats/object/matched_ious: 0.2469, loss: 2.8997, grad_norm: 9.1492
2024-09-03 23:00:23,665 - mmdet3d - INFO - Epoch [1][1650/8000]	lr: 1.000e-04, eta: 1 day, 11:11:05, time: 1.377, data_time: 0.306, memory: 6889, loss/object/loss_heatmap: 1.0961, loss/object/layer_-1_loss_cls: 0.0992, loss/object/layer_-1_loss_bbox: 1.9200, stats/object/matched_ious: 0.2458, loss: 3.1153, grad_norm: 8.3240
2024-09-03 23:01:34,728 - mmdet3d - INFO - Epoch [1][1700/8000]	lr: 1.000e-04, eta: 1 day, 11:02:14, time: 1.421, data_time: 0.352, memory: 6897, loss/object/loss_heatmap: 0.9838, loss/object/layer_-1_loss_cls: 0.0965, loss/object/layer_-1_loss_bbox: 1.6530, stats/object/matched_ious: 0.2654, loss: 2.7333, grad_norm: 8.3737
2024-09-03 23:02:47,369 - mmdet3d - INFO - Epoch [1][1750/8000]	lr: 1.000e-04, eta: 1 day, 10:55:00, time: 1.453, data_time: 0.330, memory: 6897, loss/object/loss_heatmap: 1.0406, loss/object/layer_-1_loss_cls: 0.0985, loss/object/layer_-1_loss_bbox: 1.8053, stats/object/matched_ious: 0.2697, loss: 2.9444, grad_norm: 8.8174
2024-09-03 23:03:59,140 - mmdet3d - INFO - Epoch [1][1800/8000]	lr: 1.000e-04, eta: 1 day, 10:47:28, time: 1.435, data_time: 0.347, memory: 6897, loss/object/loss_heatmap: 0.9250, loss/object/layer_-1_loss_cls: 0.0852, loss/object/layer_-1_loss_bbox: 1.6048, stats/object/matched_ious: 0.2950, loss: 2.6150, grad_norm: 8.4609
2024-09-03 23:05:12,013 - mmdet3d - INFO - Epoch [1][1850/8000]	lr: 1.000e-04, eta: 1 day, 10:41:03, time: 1.457, data_time: 0.361, memory: 6897, loss/object/loss_heatmap: 0.9666, loss/object/layer_-1_loss_cls: 0.0924, loss/object/layer_-1_loss_bbox: 1.6859, stats/object/matched_ious: 0.2847, loss: 2.7448, grad_norm: 8.6755
2024-09-03 23:06:20,211 - mmdet3d - INFO - Epoch [1][1900/8000]	lr: 1.000e-04, eta: 1 day, 10:31:43, time: 1.364, data_time: 0.277, memory: 6897, loss/object/loss_heatmap: 0.9222, loss/object/layer_-1_loss_cls: 0.0858, loss/object/layer_-1_loss_bbox: 1.6395, stats/object/matched_ious: 0.2922, loss: 2.6475, grad_norm: 8.7484
2024-09-03 23:07:32,702 - mmdet3d - INFO - Epoch [1][1950/8000]	lr: 1.000e-04, eta: 1 day, 10:25:40, time: 1.450, data_time: 0.353, memory: 6897, loss/object/loss_heatmap: 0.9351, loss/object/layer_-1_loss_cls: 0.0852, loss/object/layer_-1_loss_bbox: 1.7406, stats/object/matched_ious: 0.2841, loss: 2.7609, grad_norm: 7.7691
2024-09-03 23:08:49,109 - mmdet3d - INFO - Epoch [1][2000/8000]	lr: 1.000e-04, eta: 1 day, 10:22:24, time: 1.528, data_time: 0.416, memory: 6897, loss/object/loss_heatmap: 0.9453, loss/object/layer_-1_loss_cls: 0.0897, loss/object/layer_-1_loss_bbox: 1.5632, stats/object/matched_ious: 0.2822, loss: 2.5982, grad_norm: 9.0822
2024-09-03 23:10:01,793 - mmdet3d - INFO - Epoch [1][2050/8000]	lr: 1.000e-04, eta: 1 day, 10:16:52, time: 1.454, data_time: 0.377, memory: 6897, loss/object/loss_heatmap: 0.9221, loss/object/layer_-1_loss_cls: 0.0896, loss/object/layer_-1_loss_bbox: 1.5814, stats/object/matched_ious: 0.2897, loss: 2.5931, grad_norm: 7.7523
2024-09-03 23:11:15,378 - mmdet3d - INFO - Epoch [1][2100/8000]	lr: 1.000e-04, eta: 1 day, 10:12:06, time: 1.472, data_time: 0.415, memory: 6897, loss/object/loss_heatmap: 0.9960, loss/object/layer_-1_loss_cls: 0.0962, loss/object/layer_-1_loss_bbox: 1.6492, stats/object/matched_ious: 0.2857, loss: 2.7413, grad_norm: 8.4877
2024-09-03 23:12:30,393 - mmdet3d - INFO - Epoch [1][2150/8000]	lr: 1.000e-04, eta: 1 day, 10:08:22, time: 1.500, data_time: 0.421, memory: 6897, loss/object/loss_heatmap: 0.9386, loss/object/layer_-1_loss_cls: 0.0881, loss/object/layer_-1_loss_bbox: 1.6508, stats/object/matched_ious: 0.2929, loss: 2.6775, grad_norm: 7.2111
2024-09-03 23:13:38,261 - mmdet3d - INFO - Epoch [1][2200/8000]	lr: 1.000e-04, eta: 1 day, 10:00:31, time: 1.357, data_time: 0.292, memory: 6897, loss/object/loss_heatmap: 0.9868, loss/object/layer_-1_loss_cls: 0.0888, loss/object/layer_-1_loss_bbox: 1.7890, stats/object/matched_ious: 0.2962, loss: 2.8646, grad_norm: 7.1202
2024-09-03 23:14:53,636 - mmdet3d - INFO - Epoch [1][2250/8000]	lr: 1.000e-04, eta: 1 day, 9:57:18, time: 1.507, data_time: 0.410, memory: 6897, loss/object/loss_heatmap: 0.9259, loss/object/layer_-1_loss_cls: 0.0856, loss/object/layer_-1_loss_bbox: 1.6495, stats/object/matched_ious: 0.3011, loss: 2.6610, grad_norm: 9.9541
2024-09-03 23:16:08,532 - mmdet3d - INFO - Epoch [1][2300/8000]	lr: 1.000e-04, eta: 1 day, 9:53:54, time: 1.498, data_time: 0.446, memory: 6897, loss/object/loss_heatmap: 0.9530, loss/object/layer_-1_loss_cls: 0.0953, loss/object/layer_-1_loss_bbox: 1.4944, stats/object/matched_ious: 0.3085, loss: 2.5427, grad_norm: 7.6249
2024-09-03 23:17:17,502 - mmdet3d - INFO - Epoch [1][2350/8000]	lr: 1.000e-04, eta: 1 day, 9:47:20, time: 1.379, data_time: 0.322, memory: 6897, loss/object/loss_heatmap: 0.9855, loss/object/layer_-1_loss_cls: 0.0931, loss/object/layer_-1_loss_bbox: 1.6442, stats/object/matched_ious: 0.2952, loss: 2.7227, grad_norm: 7.0454
2024-09-03 23:18:29,157 - mmdet3d - INFO - Epoch [1][2400/8000]	lr: 1.000e-04, eta: 1 day, 9:42:26, time: 1.433, data_time: 0.351, memory: 6897, loss/object/loss_heatmap: 0.9873, loss/object/layer_-1_loss_cls: 0.0884, loss/object/layer_-1_loss_bbox: 1.7782, stats/object/matched_ious: 0.2867, loss: 2.8540, grad_norm: 8.2982
2024-09-03 23:19:42,585 - mmdet3d - INFO - Epoch [1][2450/8000]	lr: 1.000e-04, eta: 1 day, 9:38:37, time: 1.469, data_time: 0.377, memory: 6897, loss/object/loss_heatmap: 0.9287, loss/object/layer_-1_loss_cls: 0.0892, loss/object/layer_-1_loss_bbox: 1.6198, stats/object/matched_ious: 0.3106, loss: 2.6377, grad_norm: 8.1092
2024-09-03 23:20:52,838 - mmdet3d - INFO - Epoch [1][2500/8000]	lr: 1.000e-04, eta: 1 day, 9:33:16, time: 1.405, data_time: 0.357, memory: 6897, loss/object/loss_heatmap: 0.9705, loss/object/layer_-1_loss_cls: 0.0905, loss/object/layer_-1_loss_bbox: 1.7338, stats/object/matched_ious: 0.2990, loss: 2.7948, grad_norm: 8.3327
2024-09-03 23:22:07,049 - mmdet3d - INFO - Epoch [1][2550/8000]	lr: 1.000e-04, eta: 1 day, 9:30:05, time: 1.484, data_time: 0.413, memory: 6897, loss/object/loss_heatmap: 0.9216, loss/object/layer_-1_loss_cls: 0.0834, loss/object/layer_-1_loss_bbox: 1.5836, stats/object/matched_ious: 0.3022, loss: 2.5886, grad_norm: 7.8157
2024-09-03 23:23:18,734 - mmdet3d - INFO - Epoch [1][2600/8000]	lr: 1.000e-04, eta: 1 day, 9:25:43, time: 1.434, data_time: 0.359, memory: 6897, loss/object/loss_heatmap: 0.8907, loss/object/layer_-1_loss_cls: 0.0838, loss/object/layer_-1_loss_bbox: 1.5684, stats/object/matched_ious: 0.3269, loss: 2.5429, grad_norm: 7.7281
2024-09-03 23:24:32,421 - mmdet3d - INFO - Epoch [1][2650/8000]	lr: 1.000e-04, eta: 1 day, 9:22:27, time: 1.474, data_time: 0.395, memory: 6897, loss/object/loss_heatmap: 0.9521, loss/object/layer_-1_loss_cls: 0.0909, loss/object/layer_-1_loss_bbox: 1.5874, stats/object/matched_ious: 0.3115, loss: 2.6303, grad_norm: 8.5650
2024-09-03 23:25:41,216 - mmdet3d - INFO - Epoch [1][2700/8000]	lr: 1.000e-04, eta: 1 day, 9:16:55, time: 1.376, data_time: 0.331, memory: 6897, loss/object/loss_heatmap: 0.8618, loss/object/layer_-1_loss_cls: 0.0859, loss/object/layer_-1_loss_bbox: 1.4020, stats/object/matched_ious: 0.3247, loss: 2.3497, grad_norm: 10.1496
2024-09-03 23:26:51,074 - mmdet3d - INFO - Epoch [1][2750/8000]	lr: 1.000e-04, eta: 1 day, 9:12:03, time: 1.397, data_time: 0.314, memory: 6897, loss/object/loss_heatmap: 0.8680, loss/object/layer_-1_loss_cls: 0.0795, loss/object/layer_-1_loss_bbox: 1.6541, stats/object/matched_ious: 0.3279, loss: 2.6016, grad_norm: 7.1674
2024-09-03 23:27:58,206 - mmdet3d - INFO - Epoch [1][2800/8000]	lr: 1.000e-04, eta: 1 day, 9:06:04, time: 1.343, data_time: 0.289, memory: 6897, loss/object/loss_heatmap: 0.9500, loss/object/layer_-1_loss_cls: 0.0953, loss/object/layer_-1_loss_bbox: 1.7084, stats/object/matched_ious: 0.3102, loss: 2.7537, grad_norm: 7.8106
2024-09-03 23:29:08,549 - mmdet3d - INFO - Epoch [1][2850/8000]	lr: 1.000e-04, eta: 1 day, 9:01:41, time: 1.407, data_time: 0.344, memory: 6897, loss/object/loss_heatmap: 0.9310, loss/object/layer_-1_loss_cls: 0.0836, loss/object/layer_-1_loss_bbox: 1.6971, stats/object/matched_ious: 0.3247, loss: 2.7118, grad_norm: 7.6988
2024-09-03 23:30:16,178 - mmdet3d - INFO - Epoch [1][2900/8000]	lr: 1.000e-04, eta: 1 day, 8:56:14, time: 1.353, data_time: 0.309, memory: 6897, loss/object/loss_heatmap: 0.9149, loss/object/layer_-1_loss_cls: 0.0862, loss/object/layer_-1_loss_bbox: 1.6310, stats/object/matched_ious: 0.3340, loss: 2.6321, grad_norm: 7.3970
2024-09-03 23:31:23,653 - mmdet3d - INFO - Epoch [1][2950/8000]	lr: 1.000e-04, eta: 1 day, 8:50:51, time: 1.349, data_time: 0.292, memory: 6897, loss/object/loss_heatmap: 0.9404, loss/object/layer_-1_loss_cls: 0.0849, loss/object/layer_-1_loss_bbox: 1.6401, stats/object/matched_ious: 0.3338, loss: 2.6654, grad_norm: 7.8917
2024-09-03 23:32:42,821 - mmdet3d - INFO - Epoch [1][3000/8000]	lr: 1.000e-04, eta: 1 day, 8:50:36, time: 1.583, data_time: 0.499, memory: 6897, loss/object/loss_heatmap: 0.8877, loss/object/layer_-1_loss_cls: 0.0843, loss/object/layer_-1_loss_bbox: 1.5301, stats/object/matched_ious: 0.3352, loss: 2.5021, grad_norm: 7.7727
2024-09-03 23:33:51,012 - mmdet3d - INFO - Epoch [1][3050/8000]	lr: 1.000e-04, eta: 1 day, 8:45:43, time: 1.364, data_time: 0.326, memory: 6897, loss/object/loss_heatmap: 0.9348, loss/object/layer_-1_loss_cls: 0.0902, loss/object/layer_-1_loss_bbox: 1.6265, stats/object/matched_ious: 0.3468, loss: 2.6515, grad_norm: 8.2678
2024-09-03 23:34:58,260 - mmdet3d - INFO - Epoch [1][3100/8000]	lr: 1.000e-04, eta: 1 day, 8:40:33, time: 1.345, data_time: 0.290, memory: 6897, loss/object/loss_heatmap: 0.9636, loss/object/layer_-1_loss_cls: 0.0965, loss/object/layer_-1_loss_bbox: 1.4522, stats/object/matched_ious: 0.3482, loss: 2.5123, grad_norm: 8.7530
2024-09-03 23:36:07,300 - mmdet3d - INFO - Epoch [1][3150/8000]	lr: 1.000e-04, eta: 1 day, 8:36:15, time: 1.381, data_time: 0.346, memory: 6897, loss/object/loss_heatmap: 0.8948, loss/object/layer_-1_loss_cls: 0.0831, loss/object/layer_-1_loss_bbox: 1.4884, stats/object/matched_ious: 0.3490, loss: 2.4662, grad_norm: 8.2988
2024-09-03 23:37:13,987 - mmdet3d - INFO - Epoch [1][3200/8000]	lr: 1.000e-04, eta: 1 day, 8:31:07, time: 1.334, data_time: 0.297, memory: 6897, loss/object/loss_heatmap: 0.9562, loss/object/layer_-1_loss_cls: 0.0907, loss/object/layer_-1_loss_bbox: 1.6134, stats/object/matched_ious: 0.3427, loss: 2.6602, grad_norm: 10.5305
2024-09-03 23:38:22,606 - mmdet3d - INFO - Epoch [1][3250/8000]	lr: 1.000e-04, eta: 1 day, 8:26:51, time: 1.372, data_time: 0.297, memory: 6897, loss/object/loss_heatmap: 0.8741, loss/object/layer_-1_loss_cls: 0.0784, loss/object/layer_-1_loss_bbox: 1.3924, stats/object/matched_ious: 0.3709, loss: 2.3449, grad_norm: 7.1616
2024-09-03 23:39:29,171 - mmdet3d - INFO - Epoch [1][3300/8000]	lr: 1.000e-04, eta: 1 day, 8:21:53, time: 1.331, data_time: 0.293, memory: 6897, loss/object/loss_heatmap: 0.9423, loss/object/layer_-1_loss_cls: 0.0881, loss/object/layer_-1_loss_bbox: 1.6532, stats/object/matched_ious: 0.3525, loss: 2.6836, grad_norm: 7.4989
2024-09-03 23:40:39,238 - mmdet3d - INFO - Epoch [1][3350/8000]	lr: 1.000e-04, eta: 1 day, 8:18:23, time: 1.401, data_time: 0.331, memory: 6897, loss/object/loss_heatmap: 0.9641, loss/object/layer_-1_loss_cls: 0.0931, loss/object/layer_-1_loss_bbox: 1.5952, stats/object/matched_ious: 0.3591, loss: 2.6525, grad_norm: 6.8855
2024-09-03 23:41:49,371 - mmdet3d - INFO - Epoch [1][3400/8000]	lr: 1.000e-04, eta: 1 day, 8:14:58, time: 1.403, data_time: 0.347, memory: 6897, loss/object/loss_heatmap: 0.8523, loss/object/layer_-1_loss_cls: 0.0849, loss/object/layer_-1_loss_bbox: 1.4492, stats/object/matched_ious: 0.3779, loss: 2.3864, grad_norm: 8.6437
2024-09-03 23:42:53,657 - mmdet3d - INFO - Epoch [1][3450/8000]	lr: 1.000e-04, eta: 1 day, 8:09:27, time: 1.286, data_time: 0.240, memory: 6897, loss/object/loss_heatmap: 0.8609, loss/object/layer_-1_loss_cls: 0.0833, loss/object/layer_-1_loss_bbox: 1.4846, stats/object/matched_ious: 0.3731, loss: 2.4287, grad_norm: 7.9911
2024-09-03 23:44:02,042 - mmdet3d - INFO - Epoch [1][3500/8000]	lr: 1.000e-04, eta: 1 day, 8:05:33, time: 1.368, data_time: 0.321, memory: 6897, loss/object/loss_heatmap: 0.8467, loss/object/layer_-1_loss_cls: 0.0822, loss/object/layer_-1_loss_bbox: 1.4170, stats/object/matched_ious: 0.3840, loss: 2.3460, grad_norm: 6.4313
2024-09-03 23:45:06,646 - mmdet3d - INFO - Epoch [1][3550/8000]	lr: 1.000e-04, eta: 1 day, 8:00:23, time: 1.292, data_time: 0.244, memory: 6897, loss/object/loss_heatmap: 0.9367, loss/object/layer_-1_loss_cls: 0.0855, loss/object/layer_-1_loss_bbox: 1.6097, stats/object/matched_ious: 0.3698, loss: 2.6319, grad_norm: 6.9601
2024-09-03 23:46:10,363 - mmdet3d - INFO - Epoch [1][3600/8000]	lr: 1.000e-04, eta: 1 day, 7:55:00, time: 1.274, data_time: 0.238, memory: 6897, loss/object/loss_heatmap: 0.8879, loss/object/layer_-1_loss_cls: 0.0829, loss/object/layer_-1_loss_bbox: 1.5024, stats/object/matched_ious: 0.3879, loss: 2.4732, grad_norm: 7.3322
2024-09-03 23:47:18,937 - mmdet3d - INFO - Epoch [1][3650/8000]	lr: 1.000e-04, eta: 1 day, 7:51:26, time: 1.371, data_time: 0.315, memory: 6897, loss/object/loss_heatmap: 0.9047, loss/object/layer_-1_loss_cls: 0.0903, loss/object/layer_-1_loss_bbox: 1.4445, stats/object/matched_ious: 0.3864, loss: 2.4395, grad_norm: 7.7272
2024-09-03 23:48:28,105 - mmdet3d - INFO - Epoch [1][3700/8000]	lr: 1.000e-04, eta: 1 day, 7:48:09, time: 1.383, data_time: 0.343, memory: 6897, loss/object/loss_heatmap: 0.9692, loss/object/layer_-1_loss_cls: 0.0911, loss/object/layer_-1_loss_bbox: 1.6496, stats/object/matched_ious: 0.3580, loss: 2.7099, grad_norm: 7.0232
2024-09-03 23:49:35,662 - mmdet3d - INFO - Epoch [1][3750/8000]	lr: 1.000e-04, eta: 1 day, 7:44:22, time: 1.351, data_time: 0.265, memory: 6897, loss/object/loss_heatmap: 0.9438, loss/object/layer_-1_loss_cls: 0.0825, loss/object/layer_-1_loss_bbox: 1.6373, stats/object/matched_ious: 0.3824, loss: 2.6635, grad_norm: 6.2414
2024-09-03 23:50:41,281 - mmdet3d - INFO - Epoch [1][3800/8000]	lr: 1.000e-04, eta: 1 day, 7:40:00, time: 1.312, data_time: 0.249, memory: 6897, loss/object/loss_heatmap: 0.9685, loss/object/layer_-1_loss_cls: 0.0937, loss/object/layer_-1_loss_bbox: 1.6500, stats/object/matched_ious: 0.3701, loss: 2.7123, grad_norm: 7.0015
2024-09-03 23:51:49,096 - mmdet3d - INFO - Epoch [1][3850/8000]	lr: 1.000e-04, eta: 1 day, 7:36:27, time: 1.356, data_time: 0.263, memory: 6897, loss/object/loss_heatmap: 0.8684, loss/object/layer_-1_loss_cls: 0.0785, loss/object/layer_-1_loss_bbox: 1.4769, stats/object/matched_ious: 0.3805, loss: 2.4238, grad_norm: 10.0102
2024-09-03 23:52:53,560 - mmdet3d - INFO - Epoch [1][3900/8000]	lr: 1.000e-04, eta: 1 day, 7:31:53, time: 1.289, data_time: 0.221, memory: 6897, loss/object/loss_heatmap: 0.9127, loss/object/layer_-1_loss_cls: 0.0820, loss/object/layer_-1_loss_bbox: 1.6023, stats/object/matched_ious: 0.3527, loss: 2.5970, grad_norm: 6.5263
2024-09-03 23:54:03,034 - mmdet3d - INFO - Epoch [1][3950/8000]	lr: 1.000e-04, eta: 1 day, 7:29:00, time: 1.389, data_time: 0.315, memory: 6897, loss/object/loss_heatmap: 0.9368, loss/object/layer_-1_loss_cls: 0.0921, loss/object/layer_-1_loss_bbox: 1.6152, stats/object/matched_ious: 0.3711, loss: 2.6442, grad_norm: 6.9795
2024-09-03 23:55:08,911 - mmdet3d - INFO - Epoch [1][4000/8000]	lr: 1.000e-04, eta: 1 day, 7:25:01, time: 1.318, data_time: 0.213, memory: 6897, loss/object/loss_heatmap: 0.9340, loss/object/layer_-1_loss_cls: 0.0862, loss/object/layer_-1_loss_bbox: 1.6689, stats/object/matched_ious: 0.3755, loss: 2.6891, grad_norm: 6.4199
2024-09-03 23:56:14,447 - mmdet3d - INFO - Epoch [1][4050/8000]	lr: 1.000e-04, eta: 1 day, 7:21:00, time: 1.311, data_time: 0.244, memory: 6897, loss/object/loss_heatmap: 0.8624, loss/object/layer_-1_loss_cls: 0.0804, loss/object/layer_-1_loss_bbox: 1.4676, stats/object/matched_ious: 0.4000, loss: 2.4104, grad_norm: 7.0941
2024-09-03 23:57:17,968 - mmdet3d - INFO - Epoch [1][4100/8000]	lr: 1.000e-04, eta: 1 day, 7:16:26, time: 1.270, data_time: 0.191, memory: 6897, loss/object/loss_heatmap: 0.9230, loss/object/layer_-1_loss_cls: 0.0855, loss/object/layer_-1_loss_bbox: 1.6351, stats/object/matched_ious: 0.3731, loss: 2.6437, grad_norm: 7.1104
2024-09-03 23:58:22,547 - mmdet3d - INFO - Epoch [1][4150/8000]	lr: 1.000e-04, eta: 1 day, 7:12:17, time: 1.292, data_time: 0.222, memory: 6897, loss/object/loss_heatmap: 0.8664, loss/object/layer_-1_loss_cls: 0.0843, loss/object/layer_-1_loss_bbox: 1.4496, stats/object/matched_ious: 0.4047, loss: 2.4004, grad_norm: 5.8733
2024-09-03 23:59:23,432 - mmdet3d - INFO - Epoch [1][4200/8000]	lr: 1.000e-04, eta: 1 day, 7:07:05, time: 1.218, data_time: 0.169, memory: 6897, loss/object/loss_heatmap: 0.9093, loss/object/layer_-1_loss_cls: 0.0855, loss/object/layer_-1_loss_bbox: 1.5153, stats/object/matched_ious: 0.3903, loss: 2.5101, grad_norm: 7.2788
2024-09-04 00:00:26,120 - mmdet3d - INFO - Epoch [1][4250/8000]	lr: 1.000e-04, eta: 1 day, 7:02:32, time: 1.254, data_time: 0.165, memory: 6897, loss/object/loss_heatmap: 0.9083, loss/object/layer_-1_loss_cls: 0.0916, loss/object/layer_-1_loss_bbox: 1.4487, stats/object/matched_ious: 0.3997, loss: 2.4486, grad_norm: 8.0361
2024-09-04 00:01:31,958 - mmdet3d - INFO - Epoch [1][4300/8000]	lr: 1.000e-04, eta: 1 day, 6:58:58, time: 1.317, data_time: 0.240, memory: 6897, loss/object/loss_heatmap: 0.9047, loss/object/layer_-1_loss_cls: 0.0888, loss/object/layer_-1_loss_bbox: 1.4637, stats/object/matched_ious: 0.3877, loss: 2.4573, grad_norm: 6.5375
2024-09-04 00:02:31,890 - mmdet3d - INFO - Epoch [1][4350/8000]	lr: 1.000e-04, eta: 1 day, 6:53:46, time: 1.199, data_time: 0.141, memory: 6897, loss/object/loss_heatmap: 0.9292, loss/object/layer_-1_loss_cls: 0.0900, loss/object/layer_-1_loss_bbox: 1.4533, stats/object/matched_ious: 0.3932, loss: 2.4724, grad_norm: 6.3980
2024-09-04 00:03:31,883 - mmdet3d - INFO - Epoch [1][4400/8000]	lr: 1.000e-04, eta: 1 day, 6:48:40, time: 1.200, data_time: 0.135, memory: 6897, loss/object/loss_heatmap: 0.8387, loss/object/layer_-1_loss_cls: 0.1051, loss/object/layer_-1_loss_bbox: 1.2133, stats/object/matched_ious: 0.4192, loss: 2.1571, grad_norm: 6.4138
2024-09-04 00:04:34,738 - mmdet3d - INFO - Epoch [1][4450/8000]	lr: 1.000e-04, eta: 1 day, 6:44:28, time: 1.257, data_time: 0.196, memory: 6897, loss/object/loss_heatmap: 0.8893, loss/object/layer_-1_loss_cls: 0.0889, loss/object/layer_-1_loss_bbox: 1.5608, stats/object/matched_ious: 0.4020, loss: 2.5391, grad_norm: 7.2898
2024-09-04 00:05:37,656 - mmdet3d - INFO - Epoch [1][4500/8000]	lr: 1.000e-04, eta: 1 day, 6:40:22, time: 1.258, data_time: 0.180, memory: 6897, loss/object/loss_heatmap: 0.8878, loss/object/layer_-1_loss_cls: 0.0817, loss/object/layer_-1_loss_bbox: 1.5892, stats/object/matched_ious: 0.3884, loss: 2.5587, grad_norm: 6.3216
2024-09-04 00:06:41,204 - mmdet3d - INFO - Epoch [1][4550/8000]	lr: 1.000e-04, eta: 1 day, 6:36:30, time: 1.271, data_time: 0.202, memory: 6897, loss/object/loss_heatmap: 0.8933, loss/object/layer_-1_loss_cls: 0.0803, loss/object/layer_-1_loss_bbox: 1.5562, stats/object/matched_ious: 0.4012, loss: 2.5298, grad_norm: 5.5414
2024-09-04 00:07:44,152 - mmdet3d - INFO - Epoch [1][4600/8000]	lr: 1.000e-04, eta: 1 day, 6:32:32, time: 1.259, data_time: 0.204, memory: 6897, loss/object/loss_heatmap: 0.9330, loss/object/layer_-1_loss_cls: 0.0847, loss/object/layer_-1_loss_bbox: 1.5231, stats/object/matched_ious: 0.4035, loss: 2.5407, grad_norm: 5.8440
2024-09-04 00:08:45,724 - mmdet3d - INFO - Epoch [1][4650/8000]	lr: 1.000e-04, eta: 1 day, 6:28:15, time: 1.231, data_time: 0.161, memory: 6897, loss/object/loss_heatmap: 0.8616, loss/object/layer_-1_loss_cls: 0.0866, loss/object/layer_-1_loss_bbox: 1.4295, stats/object/matched_ious: 0.4181, loss: 2.3776, grad_norm: 6.4100
2024-09-04 00:09:43,701 - mmdet3d - INFO - Epoch [1][4700/8000]	lr: 1.000e-04, eta: 1 day, 6:23:05, time: 1.160, data_time: 0.111, memory: 6897, loss/object/loss_heatmap: 0.8321, loss/object/layer_-1_loss_cls: 0.0765, loss/object/layer_-1_loss_bbox: 1.4412, stats/object/matched_ious: 0.4127, loss: 2.3499, grad_norm: 5.6444
2024-09-04 00:10:48,952 - mmdet3d - INFO - Epoch [1][4750/8000]	lr: 1.000e-04, eta: 1 day, 6:19:55, time: 1.305, data_time: 0.245, memory: 6897, loss/object/loss_heatmap: 0.8534, loss/object/layer_-1_loss_cls: 0.0850, loss/object/layer_-1_loss_bbox: 1.4372, stats/object/matched_ious: 0.4054, loss: 2.3756, grad_norm: 6.2846
2024-09-04 00:11:53,809 - mmdet3d - INFO - Epoch [1][4800/8000]	lr: 1.000e-04, eta: 1 day, 6:16:42, time: 1.297, data_time: 0.224, memory: 6897, loss/object/loss_heatmap: 0.8652, loss/object/layer_-1_loss_cls: 0.0907, loss/object/layer_-1_loss_bbox: 1.3803, stats/object/matched_ious: 0.4041, loss: 2.3363, grad_norm: 6.9074
2024-09-04 00:12:55,454 - mmdet3d - INFO - Epoch [1][4850/8000]	lr: 1.000e-04, eta: 1 day, 6:12:42, time: 1.233, data_time: 0.196, memory: 6897, loss/object/loss_heatmap: 0.8538, loss/object/layer_-1_loss_cls: 0.0854, loss/object/layer_-1_loss_bbox: 1.3993, stats/object/matched_ious: 0.4140, loss: 2.3385, grad_norm: 5.8267
2024-09-04 00:13:56,661 - mmdet3d - INFO - Epoch [1][4900/8000]	lr: 1.000e-04, eta: 1 day, 6:08:38, time: 1.224, data_time: 0.152, memory: 6897, loss/object/loss_heatmap: 0.8698, loss/object/layer_-1_loss_cls: 0.0803, loss/object/layer_-1_loss_bbox: 1.4950, stats/object/matched_ious: 0.4228, loss: 2.4451, grad_norm: 5.5791
2024-09-04 00:14:58,282 - mmdet3d - INFO - Epoch [1][4950/8000]	lr: 1.000e-04, eta: 1 day, 6:04:45, time: 1.232, data_time: 0.183, memory: 6897, loss/object/loss_heatmap: 0.8596, loss/object/layer_-1_loss_cls: 0.0869, loss/object/layer_-1_loss_bbox: 1.4303, stats/object/matched_ious: 0.4044, loss: 2.3768, grad_norm: 5.7209
2024-09-04 00:15:58,505 - mmdet3d - INFO - Epoch [1][5000/8000]	lr: 1.000e-04, eta: 1 day, 6:00:34, time: 1.204, data_time: 0.150, memory: 6897, loss/object/loss_heatmap: 0.9469, loss/object/layer_-1_loss_cls: 0.0792, loss/object/layer_-1_loss_bbox: 1.7081, stats/object/matched_ious: 0.4071, loss: 2.7341, grad_norm: 5.4443
2024-09-04 00:16:59,422 - mmdet3d - INFO - Epoch [1][5050/8000]	lr: 1.000e-04, eta: 1 day, 5:56:37, time: 1.218, data_time: 0.142, memory: 6897, loss/object/loss_heatmap: 0.8227, loss/object/layer_-1_loss_cls: 0.0788, loss/object/layer_-1_loss_bbox: 1.3102, stats/object/matched_ious: 0.4231, loss: 2.2117, grad_norm: 5.5897
2024-09-04 00:18:02,501 - mmdet3d - INFO - Epoch [1][5100/8000]	lr: 1.000e-04, eta: 1 day, 5:53:16, time: 1.262, data_time: 0.218, memory: 6897, loss/object/loss_heatmap: 0.8208, loss/object/layer_-1_loss_cls: 0.0748, loss/object/layer_-1_loss_bbox: 1.4607, stats/object/matched_ious: 0.4232, loss: 2.3563, grad_norm: 5.0367
2024-09-04 00:19:06,302 - mmdet3d - INFO - Epoch [1][5150/8000]	lr: 1.000e-04, eta: 1 day, 5:50:07, time: 1.276, data_time: 0.233, memory: 6897, loss/object/loss_heatmap: 0.8449, loss/object/layer_-1_loss_cls: 0.0767, loss/object/layer_-1_loss_bbox: 1.4467, stats/object/matched_ious: 0.4208, loss: 2.3683, grad_norm: 6.3591
2024-09-04 00:20:05,862 - mmdet3d - INFO - Epoch [1][5200/8000]	lr: 1.000e-04, eta: 1 day, 5:46:00, time: 1.191, data_time: 0.128, memory: 6897, loss/object/loss_heatmap: 0.8154, loss/object/layer_-1_loss_cls: 0.0737, loss/object/layer_-1_loss_bbox: 1.3135, stats/object/matched_ious: 0.4281, loss: 2.2026, grad_norm: 5.5988
2024-09-04 00:21:06,269 - mmdet3d - INFO - Epoch [1][5250/8000]	lr: 1.000e-04, eta: 1 day, 5:42:09, time: 1.208, data_time: 0.137, memory: 6897, loss/object/loss_heatmap: 0.9207, loss/object/layer_-1_loss_cls: 0.0841, loss/object/layer_-1_loss_bbox: 1.5577, stats/object/matched_ious: 0.4067, loss: 2.5625, grad_norm: 6.1047
2024-09-04 00:22:10,097 - mmdet3d - INFO - Epoch [1][5300/8000]	lr: 1.000e-04, eta: 1 day, 5:39:08, time: 1.277, data_time: 0.204, memory: 6897, loss/object/loss_heatmap: 0.8330, loss/object/layer_-1_loss_cls: 0.0790, loss/object/layer_-1_loss_bbox: 1.4449, stats/object/matched_ious: 0.4245, loss: 2.3569, grad_norm: 5.8789
2024-09-04 00:23:16,096 - mmdet3d - INFO - Epoch [1][5350/8000]	lr: 1.000e-04, eta: 1 day, 5:36:41, time: 1.320, data_time: 0.218, memory: 6897, loss/object/loss_heatmap: 0.9668, loss/object/layer_-1_loss_cls: 0.0940, loss/object/layer_-1_loss_bbox: 1.6578, stats/object/matched_ious: 0.4099, loss: 2.7186, grad_norm: 6.4994
2024-09-04 00:24:17,869 - mmdet3d - INFO - Epoch [1][5400/8000]	lr: 1.000e-04, eta: 1 day, 5:33:17, time: 1.235, data_time: 0.141, memory: 6897, loss/object/loss_heatmap: 0.8755, loss/object/layer_-1_loss_cls: 0.0798, loss/object/layer_-1_loss_bbox: 1.3845, stats/object/matched_ious: 0.4204, loss: 2.3399, grad_norm: 5.6321
2024-09-04 00:25:17,627 - mmdet3d - INFO - Epoch [1][5450/8000]	lr: 1.000e-04, eta: 1 day, 5:29:27, time: 1.195, data_time: 0.122, memory: 6897, loss/object/loss_heatmap: 0.8350, loss/object/layer_-1_loss_cls: 0.0771, loss/object/layer_-1_loss_bbox: 1.3364, stats/object/matched_ious: 0.4216, loss: 2.2485, grad_norm: 5.6578
2024-09-04 00:26:18,251 - mmdet3d - INFO - Epoch [1][5500/8000]	lr: 1.000e-04, eta: 1 day, 5:25:53, time: 1.212, data_time: 0.130, memory: 6897, loss/object/loss_heatmap: 0.8594, loss/object/layer_-1_loss_cls: 0.0835, loss/object/layer_-1_loss_bbox: 1.4657, stats/object/matched_ious: 0.4217, loss: 2.4086, grad_norm: 6.6410
2024-09-04 00:27:16,649 - mmdet3d - INFO - Epoch [1][5550/8000]	lr: 1.000e-04, eta: 1 day, 5:21:51, time: 1.168, data_time: 0.092, memory: 6897, loss/object/loss_heatmap: 0.7512, loss/object/layer_-1_loss_cls: 0.0766, loss/object/layer_-1_loss_bbox: 1.2700, stats/object/matched_ious: 0.4481, loss: 2.0978, grad_norm: 6.1451
2024-09-04 00:28:21,797 - mmdet3d - INFO - Epoch [1][5600/8000]	lr: 1.000e-04, eta: 1 day, 5:19:22, time: 1.303, data_time: 0.221, memory: 6897, loss/object/loss_heatmap: 0.8685, loss/object/layer_-1_loss_cls: 0.0814, loss/object/layer_-1_loss_bbox: 1.5708, stats/object/matched_ious: 0.4074, loss: 2.5207, grad_norm: 6.2909
2024-09-04 00:29:24,330 - mmdet3d - INFO - Epoch [1][5650/8000]	lr: 1.000e-04, eta: 1 day, 5:16:21, time: 1.251, data_time: 0.145, memory: 6897, loss/object/loss_heatmap: 0.7900, loss/object/layer_-1_loss_cls: 0.0718, loss/object/layer_-1_loss_bbox: 1.3236, stats/object/matched_ious: 0.4196, loss: 2.1854, grad_norm: 5.7551
2024-09-04 00:30:24,301 - mmdet3d - INFO - Epoch [1][5700/8000]	lr: 1.000e-04, eta: 1 day, 5:12:48, time: 1.199, data_time: 0.140, memory: 6897, loss/object/loss_heatmap: 0.8366, loss/object/layer_-1_loss_cls: 0.0778, loss/object/layer_-1_loss_bbox: 1.4623, stats/object/matched_ious: 0.4142, loss: 2.3767, grad_norm: 7.2666
2024-09-04 00:31:22,045 - mmdet3d - INFO - Epoch [1][5750/8000]	lr: 1.000e-04, eta: 1 day, 5:08:49, time: 1.155, data_time: 0.079, memory: 6897, loss/object/loss_heatmap: 0.8687, loss/object/layer_-1_loss_cls: 0.0792, loss/object/layer_-1_loss_bbox: 1.5536, stats/object/matched_ious: 0.4087, loss: 2.5015, grad_norm: 5.5662
2024-09-04 00:32:21,107 - mmdet3d - INFO - Epoch [1][5800/8000]	lr: 1.000e-04, eta: 1 day, 5:05:10, time: 1.181, data_time: 0.106, memory: 6897, loss/object/loss_heatmap: 0.8135, loss/object/layer_-1_loss_cls: 0.0746, loss/object/layer_-1_loss_bbox: 1.4627, stats/object/matched_ious: 0.4385, loss: 2.3509, grad_norm: 4.9976
2024-09-04 00:33:20,479 - mmdet3d - INFO - Epoch [1][5850/8000]	lr: 1.000e-04, eta: 1 day, 5:01:37, time: 1.187, data_time: 0.144, memory: 6897, loss/object/loss_heatmap: 0.8203, loss/object/layer_-1_loss_cls: 0.0783, loss/object/layer_-1_loss_bbox: 1.2958, stats/object/matched_ious: 0.4358, loss: 2.1944, grad_norm: 5.7838
2024-09-04 00:34:23,411 - mmdet3d - INFO - Epoch [1][5900/8000]	lr: 1.000e-04, eta: 1 day, 4:58:52, time: 1.259, data_time: 0.174, memory: 6897, loss/object/loss_heatmap: 0.8833, loss/object/layer_-1_loss_cls: 0.0781, loss/object/layer_-1_loss_bbox: 1.5304, stats/object/matched_ious: 0.4243, loss: 2.4917, grad_norm: 5.5013
2024-09-04 00:35:22,466 - mmdet3d - INFO - Epoch [1][5950/8000]	lr: 1.000e-04, eta: 1 day, 4:55:21, time: 1.181, data_time: 0.095, memory: 6897, loss/object/loss_heatmap: 0.8622, loss/object/layer_-1_loss_cls: 0.0816, loss/object/layer_-1_loss_bbox: 1.5759, stats/object/matched_ious: 0.4152, loss: 2.5198, grad_norm: 5.7980
2024-09-04 00:36:26,964 - mmdet3d - INFO - Epoch [1][6000/8000]	lr: 1.000e-04, eta: 1 day, 4:52:59, time: 1.290, data_time: 0.210, memory: 6897, loss/object/loss_heatmap: 0.9279, loss/object/layer_-1_loss_cls: 0.0987, loss/object/layer_-1_loss_bbox: 1.6363, stats/object/matched_ious: 0.4222, loss: 2.6629, grad_norm: 5.8320
2024-09-04 00:37:23,229 - mmdet3d - INFO - Epoch [1][6050/8000]	lr: 1.000e-04, eta: 1 day, 4:48:58, time: 1.125, data_time: 0.049, memory: 6897, loss/object/loss_heatmap: 0.8412, loss/object/layer_-1_loss_cls: 0.0843, loss/object/layer_-1_loss_bbox: 1.4583, stats/object/matched_ious: 0.4227, loss: 2.3838, grad_norm: 5.4748
2024-09-04 00:38:20,455 - mmdet3d - INFO - Epoch [1][6100/8000]	lr: 1.000e-04, eta: 1 day, 4:45:11, time: 1.145, data_time: 0.100, memory: 6897, loss/object/loss_heatmap: 0.8997, loss/object/layer_-1_loss_cls: 0.0850, loss/object/layer_-1_loss_bbox: 1.4834, stats/object/matched_ious: 0.4226, loss: 2.4680, grad_norm: 6.1157
2024-09-04 00:39:19,667 - mmdet3d - INFO - Epoch [1][6150/8000]	lr: 1.000e-04, eta: 1 day, 4:41:51, time: 1.184, data_time: 0.119, memory: 6897, loss/object/loss_heatmap: 0.8018, loss/object/layer_-1_loss_cls: 0.0744, loss/object/layer_-1_loss_bbox: 1.3538, stats/object/matched_ious: 0.4263, loss: 2.2300, grad_norm: 5.8355
2024-09-04 00:40:20,639 - mmdet3d - INFO - Epoch [1][6200/8000]	lr: 1.000e-04, eta: 1 day, 4:38:54, time: 1.219, data_time: 0.180, memory: 6897, loss/object/loss_heatmap: 0.8257, loss/object/layer_-1_loss_cls: 0.0856, loss/object/layer_-1_loss_bbox: 1.3625, stats/object/matched_ious: 0.4386, loss: 2.2738, grad_norm: 5.5189
2024-09-04 00:41:22,285 - mmdet3d - INFO - Epoch [1][6250/8000]	lr: 1.000e-04, eta: 1 day, 4:36:07, time: 1.233, data_time: 0.195, memory: 6897, loss/object/loss_heatmap: 0.8469, loss/object/layer_-1_loss_cls: 0.0872, loss/object/layer_-1_loss_bbox: 1.3692, stats/object/matched_ious: 0.4365, loss: 2.3033, grad_norm: 6.3332
2024-09-04 00:42:22,745 - mmdet3d - INFO - Epoch [1][6300/8000]	lr: 1.000e-04, eta: 1 day, 4:33:08, time: 1.209, data_time: 0.153, memory: 6897, loss/object/loss_heatmap: 0.7857, loss/object/layer_-1_loss_cls: 0.0725, loss/object/layer_-1_loss_bbox: 1.3611, stats/object/matched_ious: 0.4525, loss: 2.2193, grad_norm: 5.2847
2024-09-04 00:43:21,622 - mmdet3d - INFO - Epoch [1][6350/8000]	lr: 1.000e-04, eta: 1 day, 4:29:52, time: 1.178, data_time: 0.134, memory: 6897, loss/object/loss_heatmap: 0.8631, loss/object/layer_-1_loss_cls: 0.0784, loss/object/layer_-1_loss_bbox: 1.4453, stats/object/matched_ious: 0.4264, loss: 2.3869, grad_norm: 5.3025
2024-09-04 00:44:18,575 - mmdet3d - INFO - Epoch [1][6400/8000]	lr: 1.000e-04, eta: 1 day, 4:26:17, time: 1.139, data_time: 0.080, memory: 6897, loss/object/loss_heatmap: 0.9076, loss/object/layer_-1_loss_cls: 0.0978, loss/object/layer_-1_loss_bbox: 1.6697, stats/object/matched_ious: 0.4196, loss: 2.6752, grad_norm: 6.2711
2024-09-04 00:45:19,092 - mmdet3d - INFO - Epoch [1][6450/8000]	lr: 1.000e-04, eta: 1 day, 4:23:24, time: 1.210, data_time: 0.163, memory: 6897, loss/object/loss_heatmap: 0.8222, loss/object/layer_-1_loss_cls: 0.0795, loss/object/layer_-1_loss_bbox: 1.3906, stats/object/matched_ious: 0.4287, loss: 2.2923, grad_norm: 6.6032
2024-09-04 00:46:17,432 - mmdet3d - INFO - Epoch [1][6500/8000]	lr: 1.000e-04, eta: 1 day, 4:20:09, time: 1.167, data_time: 0.115, memory: 6897, loss/object/loss_heatmap: 0.8373, loss/object/layer_-1_loss_cls: 0.0787, loss/object/layer_-1_loss_bbox: 1.4271, stats/object/matched_ious: 0.4316, loss: 2.3432, grad_norm: 6.0442
2024-09-04 00:47:18,774 - mmdet3d - INFO - Epoch [1][6550/8000]	lr: 1.000e-04, eta: 1 day, 4:17:29, time: 1.227, data_time: 0.177, memory: 6897, loss/object/loss_heatmap: 0.8610, loss/object/layer_-1_loss_cls: 0.0830, loss/object/layer_-1_loss_bbox: 1.3630, stats/object/matched_ious: 0.4282, loss: 2.3070, grad_norm: 5.7482
2024-09-04 00:48:16,648 - mmdet3d - INFO - Epoch [1][6600/8000]	lr: 1.000e-04, eta: 1 day, 4:14:12, time: 1.157, data_time: 0.109, memory: 6897, loss/object/loss_heatmap: 0.8439, loss/object/layer_-1_loss_cls: 0.0825, loss/object/layer_-1_loss_bbox: 1.3642, stats/object/matched_ious: 0.4304, loss: 2.2906, grad_norm: 5.4851
2024-09-04 00:49:15,064 - mmdet3d - INFO - Epoch [1][6650/8000]	lr: 1.000e-04, eta: 1 day, 4:11:03, time: 1.168, data_time: 0.120, memory: 6897, loss/object/loss_heatmap: 0.8244, loss/object/layer_-1_loss_cls: 0.0771, loss/object/layer_-1_loss_bbox: 1.4537, stats/object/matched_ious: 0.4301, loss: 2.3552, grad_norm: 5.6928
2024-09-04 00:50:15,491 - mmdet3d - INFO - Epoch [1][6700/8000]	lr: 1.000e-04, eta: 1 day, 4:08:19, time: 1.209, data_time: 0.166, memory: 6897, loss/object/loss_heatmap: 0.8445, loss/object/layer_-1_loss_cls: 0.0793, loss/object/layer_-1_loss_bbox: 1.4218, stats/object/matched_ious: 0.4336, loss: 2.3456, grad_norm: 5.4286
2024-09-04 00:51:16,695 - mmdet3d - INFO - Epoch [1][6750/8000]	lr: 1.000e-04, eta: 1 day, 4:05:44, time: 1.224, data_time: 0.170, memory: 6897, loss/object/loss_heatmap: 0.9241, loss/object/layer_-1_loss_cls: 0.0858, loss/object/layer_-1_loss_bbox: 1.4918, stats/object/matched_ious: 0.4157, loss: 2.5017, grad_norm: 6.3003
2024-09-04 00:52:16,978 - mmdet3d - INFO - Epoch [1][6800/8000]	lr: 1.000e-04, eta: 1 day, 4:03:01, time: 1.206, data_time: 0.156, memory: 6897, loss/object/loss_heatmap: 0.8103, loss/object/layer_-1_loss_cls: 0.0763, loss/object/layer_-1_loss_bbox: 1.3665, stats/object/matched_ious: 0.4393, loss: 2.2530, grad_norm: 5.7226
2024-09-04 00:53:13,288 - mmdet3d - INFO - Epoch [1][6850/8000]	lr: 1.000e-04, eta: 1 day, 3:59:36, time: 1.126, data_time: 0.093, memory: 6897, loss/object/loss_heatmap: 0.8167, loss/object/layer_-1_loss_cls: 0.0746, loss/object/layer_-1_loss_bbox: 1.4517, stats/object/matched_ious: 0.4432, loss: 2.3430, grad_norm: 5.6036
2024-09-04 00:54:10,830 - mmdet3d - INFO - Epoch [1][6900/8000]	lr: 1.000e-04, eta: 1 day, 3:56:27, time: 1.151, data_time: 0.072, memory: 6897, loss/object/loss_heatmap: 0.7735, loss/object/layer_-1_loss_cls: 0.0780, loss/object/layer_-1_loss_bbox: 1.2906, stats/object/matched_ious: 0.4633, loss: 2.1421, grad_norm: 5.0596
2024-09-04 00:55:07,761 - mmdet3d - INFO - Epoch [1][6950/8000]	lr: 1.000e-04, eta: 1 day, 3:53:14, time: 1.139, data_time: 0.069, memory: 6897, loss/object/loss_heatmap: 0.8107, loss/object/layer_-1_loss_cls: 0.0788, loss/object/layer_-1_loss_bbox: 1.3020, stats/object/matched_ious: 0.4513, loss: 2.1915, grad_norm: 4.9411
2024-09-04 00:56:04,183 - mmdet3d - INFO - Epoch [1][7000/8000]	lr: 1.000e-04, eta: 1 day, 3:49:57, time: 1.128, data_time: 0.064, memory: 6897, loss/object/loss_heatmap: 0.8311, loss/object/layer_-1_loss_cls: 0.0762, loss/object/layer_-1_loss_bbox: 1.4282, stats/object/matched_ious: 0.4401, loss: 2.3355, grad_norm: 5.5116
2024-09-04 00:56:59,771 - mmdet3d - INFO - Epoch [1][7050/8000]	lr: 1.000e-04, eta: 1 day, 3:46:33, time: 1.112, data_time: 0.063, memory: 6897, loss/object/loss_heatmap: 0.8481, loss/object/layer_-1_loss_cls: 0.0828, loss/object/layer_-1_loss_bbox: 1.3747, stats/object/matched_ious: 0.4464, loss: 2.3056, grad_norm: 5.6135
2024-09-04 00:58:01,015 - mmdet3d - INFO - Epoch [1][7100/8000]	lr: 1.000e-04, eta: 1 day, 3:44:10, time: 1.225, data_time: 0.143, memory: 6897, loss/object/loss_heatmap: 0.8446, loss/object/layer_-1_loss_cls: 0.0811, loss/object/layer_-1_loss_bbox: 1.3215, stats/object/matched_ious: 0.4397, loss: 2.2472, grad_norm: 4.8630
2024-09-04 00:58:57,973 - mmdet3d - INFO - Epoch [1][7150/8000]	lr: 1.000e-04, eta: 1 day, 3:41:04, time: 1.139, data_time: 0.091, memory: 6897, loss/object/loss_heatmap: 0.8759, loss/object/layer_-1_loss_cls: 0.0848, loss/object/layer_-1_loss_bbox: 1.5872, stats/object/matched_ious: 0.4276, loss: 2.5479, grad_norm: 5.4484
2024-09-04 01:00:04,389 - mmdet3d - INFO - Epoch [1][7200/8000]	lr: 1.000e-04, eta: 1 day, 3:39:35, time: 1.328, data_time: 0.248, memory: 6897, loss/object/loss_heatmap: 0.7867, loss/object/layer_-1_loss_cls: 0.0762, loss/object/layer_-1_loss_bbox: 1.2542, stats/object/matched_ious: 0.4465, loss: 2.1171, grad_norm: 5.1068
2024-09-04 01:01:01,514 - mmdet3d - INFO - Epoch [1][7250/8000]	lr: 1.000e-04, eta: 1 day, 3:36:34, time: 1.142, data_time: 0.090, memory: 6897, loss/object/loss_heatmap: 0.8258, loss/object/layer_-1_loss_cls: 0.0773, loss/object/layer_-1_loss_bbox: 1.4396, stats/object/matched_ious: 0.4414, loss: 2.3427, grad_norm: 5.1162
2024-09-04 01:01:57,673 - mmdet3d - INFO - Epoch [1][7300/8000]	lr: 1.000e-04, eta: 1 day, 3:33:25, time: 1.123, data_time: 0.075, memory: 6897, loss/object/loss_heatmap: 0.7877, loss/object/layer_-1_loss_cls: 0.0709, loss/object/layer_-1_loss_bbox: 1.3573, stats/object/matched_ious: 0.4486, loss: 2.2158, grad_norm: 5.2488
2024-09-04 01:02:56,351 - mmdet3d - INFO - Epoch [1][7350/8000]	lr: 1.000e-04, eta: 1 day, 3:30:42, time: 1.174, data_time: 0.133, memory: 6897, loss/object/loss_heatmap: 0.8450, loss/object/layer_-1_loss_cls: 0.0802, loss/object/layer_-1_loss_bbox: 1.3789, stats/object/matched_ious: 0.4342, loss: 2.3042, grad_norm: 5.9712
2024-09-04 01:03:56,681 - mmdet3d - INFO - Epoch [1][7400/8000]	lr: 1.000e-04, eta: 1 day, 3:28:17, time: 1.207, data_time: 0.157, memory: 6897, loss/object/loss_heatmap: 0.7575, loss/object/layer_-1_loss_cls: 0.0733, loss/object/layer_-1_loss_bbox: 1.2626, stats/object/matched_ious: 0.4426, loss: 2.0934, grad_norm: 6.2229
2024-09-04 01:04:52,381 - mmdet3d - INFO - Epoch [1][7450/8000]	lr: 1.000e-04, eta: 1 day, 3:25:08, time: 1.114, data_time: 0.056, memory: 6897, loss/object/loss_heatmap: 0.8327, loss/object/layer_-1_loss_cls: 0.0750, loss/object/layer_-1_loss_bbox: 1.5742, stats/object/matched_ious: 0.4287, loss: 2.4818, grad_norm: 4.7862
2024-09-04 01:05:56,097 - mmdet3d - INFO - Epoch [1][7500/8000]	lr: 1.000e-04, eta: 1 day, 3:23:18, time: 1.274, data_time: 0.186, memory: 6897, loss/object/loss_heatmap: 0.9163, loss/object/layer_-1_loss_cls: 0.0886, loss/object/layer_-1_loss_bbox: 1.5891, stats/object/matched_ious: 0.4377, loss: 2.5940, grad_norm: 4.9874
2024-09-04 01:06:51,774 - mmdet3d - INFO - Epoch [1][7550/8000]	lr: 1.000e-04, eta: 1 day, 3:20:12, time: 1.114, data_time: 0.032, memory: 6897, loss/object/loss_heatmap: 0.7903, loss/object/layer_-1_loss_cls: 0.0723, loss/object/layer_-1_loss_bbox: 1.2680, stats/object/matched_ious: 0.4499, loss: 2.1305, grad_norm: 5.0508
2024-09-04 01:07:47,909 - mmdet3d - INFO - Epoch [1][7600/8000]	lr: 1.000e-04, eta: 1 day, 3:17:12, time: 1.123, data_time: 0.073, memory: 6897, loss/object/loss_heatmap: 0.8116, loss/object/layer_-1_loss_cls: 0.0765, loss/object/layer_-1_loss_bbox: 1.3624, stats/object/matched_ious: 0.4443, loss: 2.2505, grad_norm: 5.3402
2024-09-04 01:08:48,569 - mmdet3d - INFO - Epoch [1][7650/8000]	lr: 1.000e-04, eta: 1 day, 3:14:56, time: 1.213, data_time: 0.128, memory: 6897, loss/object/loss_heatmap: 0.9134, loss/object/layer_-1_loss_cls: 0.0827, loss/object/layer_-1_loss_bbox: 1.5687, stats/object/matched_ious: 0.4243, loss: 2.5648, grad_norm: 5.4310
2024-09-04 01:09:47,023 - mmdet3d - INFO - Epoch [1][7700/8000]	lr: 1.000e-04, eta: 1 day, 3:12:21, time: 1.169, data_time: 0.105, memory: 6897, loss/object/loss_heatmap: 0.7817, loss/object/layer_-1_loss_cls: 0.0715, loss/object/layer_-1_loss_bbox: 1.3753, stats/object/matched_ious: 0.4570, loss: 2.2285, grad_norm: 5.3737
2024-09-04 01:10:49,462 - mmdet3d - INFO - Epoch [1][7750/8000]	lr: 1.000e-04, eta: 1 day, 3:10:24, time: 1.249, data_time: 0.191, memory: 6897, loss/object/loss_heatmap: 0.7813, loss/object/layer_-1_loss_cls: 0.0728, loss/object/layer_-1_loss_bbox: 1.2866, stats/object/matched_ious: 0.4562, loss: 2.1406, grad_norm: 4.9288
2024-09-04 01:11:45,829 - mmdet3d - INFO - Epoch [1][7800/8000]	lr: 1.000e-04, eta: 1 day, 3:07:31, time: 1.127, data_time: 0.055, memory: 6897, loss/object/loss_heatmap: 0.8449, loss/object/layer_-1_loss_cls: 0.0763, loss/object/layer_-1_loss_bbox: 1.3974, stats/object/matched_ious: 0.4501, loss: 2.3186, grad_norm: 4.7582
2024-09-04 01:12:42,576 - mmdet3d - INFO - Epoch [1][7850/8000]	lr: 1.000e-04, eta: 1 day, 3:04:43, time: 1.135, data_time: 0.045, memory: 6897, loss/object/loss_heatmap: 0.7715, loss/object/layer_-1_loss_cls: 0.0732, loss/object/layer_-1_loss_bbox: 1.2606, stats/object/matched_ious: 0.4653, loss: 2.1053, grad_norm: 4.7914
2024-09-04 01:13:41,315 - mmdet3d - INFO - Epoch [1][7900/8000]	lr: 1.000e-04, eta: 1 day, 3:02:15, time: 1.175, data_time: 0.115, memory: 6897, loss/object/loss_heatmap: 0.8808, loss/object/layer_-1_loss_cls: 0.0850, loss/object/layer_-1_loss_bbox: 1.4444, stats/object/matched_ious: 0.4391, loss: 2.4101, grad_norm: 5.3695
2024-09-04 01:14:36,183 - mmdet3d - INFO - Epoch [1][7950/8000]	lr: 1.000e-04, eta: 1 day, 2:59:13, time: 1.097, data_time: 0.039, memory: 6897, loss/object/loss_heatmap: 0.7955, loss/object/layer_-1_loss_cls: 0.0717, loss/object/layer_-1_loss_bbox: 1.2779, stats/object/matched_ious: 0.4468, loss: 2.1450, grad_norm: 4.7662
2024-09-04 01:15:35,789 - mmdet3d - INFO - Epoch [1][8000/8000]	lr: 1.000e-04, eta: 1 day, 2:56:56, time: 1.192, data_time: 0.076, memory: 6897, loss/object/loss_heatmap: 0.9168, loss/object/layer_-1_loss_cls: 0.0851, loss/object/layer_-1_loss_bbox: 1.6802, stats/object/matched_ious: 0.4368, loss: 2.6820, grad_norm: 5.4028
2024-09-04 01:15:35,952 - mmdet3d - INFO - Saving checkpoint at 1 epochs
